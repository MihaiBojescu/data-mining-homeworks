{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import typing as t\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from scipy import stats as scpy_stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib widget\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    Gender: str\n",
    "    Age: int\n",
    "    Height: float\n",
    "    Weight: float\n",
    "    family_history_with_overweight: str\n",
    "    FAVC: str\n",
    "    FCVC: int\n",
    "    NCP: int\n",
    "    CAEC: str\n",
    "    SMOKE: str\n",
    "    CH2O: int\n",
    "    SCC: str\n",
    "    FAF: str\n",
    "    TUE: int\n",
    "    CALC: str\n",
    "    MTRANS: str\n",
    "    NObeyesdad: str\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        Gender: str,\n",
    "        Age: int,\n",
    "        Height: float,\n",
    "        Weight: float,\n",
    "        family_history_with_overweight: str,\n",
    "        FAVC: str,\n",
    "        FCVC: int,\n",
    "        NCP: int,\n",
    "        CAEC: str,\n",
    "        SMOKE: str,\n",
    "        CH2O: int,\n",
    "        SCC: str,\n",
    "        FAF: int,\n",
    "        TUE: int,\n",
    "        CALC: str,\n",
    "        MTRANS: str,\n",
    "        NObeyesdad: str,\n",
    "    ):\n",
    "        self.Gender = Gender\n",
    "        self.Age = Age\n",
    "        self.Height = Height\n",
    "        self.Weight = Weight\n",
    "        self.family_history_with_overweight = family_history_with_overweight\n",
    "        self.FAVC = FAVC\n",
    "        self.FCVC = FCVC\n",
    "        self.NCP = NCP\n",
    "        self.CAEC = CAEC\n",
    "        self.SMOKE = SMOKE\n",
    "        self.CH2O = CH2O\n",
    "        self.SCC = SCC\n",
    "        self.FAF = FAF\n",
    "        self.TUE = TUE\n",
    "        self.CALC = CALC\n",
    "        self.MTRANS = MTRANS\n",
    "        self.NObeyesdad = NObeyesdad\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\n",
    "            \"{\"\n",
    "            + f'\"Gender\": \"{self.Gender}\",'\n",
    "            + f'\"Age\": {self.Age},'\n",
    "            + f'\"Height\": {self.Height},'\n",
    "            + f'\"Weight\": {self.Weight},'\n",
    "            + f'\"family_history_with_overweight\": \"{self.family_history_with_overweight}\",'\n",
    "            + f'\"FAVC\": \"{self.FAVC}\",'\n",
    "            + f'\"FCVC\": {self.FCVC},'\n",
    "            + f'\"NCP\": {self.NCP},'\n",
    "            + f'\"CAEC\": \"{self.CAEC}\",'\n",
    "            + f'\"SMOKE\": \"{self.SMOKE}\",'\n",
    "            + f'\"CH2O\": {self.CH2O},'\n",
    "            + f'\"SCC\": {self.SCC},'\n",
    "            + f'\"FAF\": \"{self.FAF}\",'\n",
    "            + f'\"TUE\": {self.TUE},'\n",
    "            + f'\"CALC\": \"{self.CALC}\",'\n",
    "            + f'\"MTRANS\": \"{self.MTRANS}\",'\n",
    "            + f'\"NObeyesdad\": \"{self.NObeyesdad}\"'\n",
    "            + \"}\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return 17\n",
    "\n",
    "    __repr__ = __str__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUMERICAL_VARIABLES = [\"Age\", \"Height\", \"Weight\", \"FCVC\", \"NCP\", \"CH2O\", \"FAF\", \"TUE\"]\n",
    "CATEGORICAL_VARIABLES = [\"FAVC\", \"CAEC\", \"CALC\", \"SCC\", \"MTRANS\", \"Gender\", \"family_history_with_overweight\", \"SMOKE\", \"NObeyesdad\"]\n",
    "\n",
    "CATEGORICAL_VARIABLES_NO_LABEL = [\"FAVC\", \"CAEC\", \"CALC\", \"SCC\", \"MTRANS\", \"Gender\", \"family_history_with_overweight\", \"SMOKE\"]\n",
    "\n",
    "LABEL_VARIABLE = \"NObeyesdad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DatasetManager:\n",
    "    def __init__(self, path_to_csv: str):\n",
    "        self.path_to_csv = path_to_csv\n",
    "\n",
    "    def load_as_obj_list(self) -> list[Person]:\n",
    "        with open(self.path_to_csv) as csv_file:\n",
    "            csv_reader = csv.DictReader(csv_file)\n",
    "            return [Person(**row) for row in csv_reader]\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    @staticmethod\n",
    "    def obj_list_to_flat_np_array(\n",
    "        data: list[Person],\n",
    "        attrs_list: list[str] = numeric_variables + categorical_values,\n",
    "    ) -> npt.NDArray[np.float32]:\n",
    "        return np.array(\n",
    "            [\n",
    "                np.float32(getattr(entry, field))\n",
    "                for entry in data\n",
    "                for field in attrs_list\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def obj_list_to_list(\n",
    "        data: t.List[Person], attrs_list: t.List[str] = categorical_values\n",
    "    ) -> t.List[t.List[str]]:\n",
    "        return [[getattr(entry, field) for field in attrs_list] for entry in data]\n",
    "\n",
    "    @staticmethod\n",
    "    def obj_list_to_flat_list(\n",
    "        data: t.List[Person], attrs_list: t.List[str] = categorical_values\n",
    "    ) -> t.List[str]:\n",
    "        return [getattr(entry, field) for field in attrs_list for entry in data]\n",
    "\n",
    "    @staticmethod\n",
    "    def make_combinations(\n",
    "        attrs_list: t.List[str], k: int = 2\n",
    "    ) -> t.List[t.Tuple[str, ...]]:\n",
    "        return [subset for subset in itertools.combinations(attrs_list, k)]\n",
    "\n",
    "    def obj_list_to_np_array(data: list[Person], attrs_list: list[str] = NUMERICAL_VARIABLES + CATEGORICAL_VARIABLES) -> np.array:\n",
    "        return np.array([[getattr(entry, field) for field in attrs_list] for entry in data])\n",
    "\n",
    "    @staticmethod\n",
    "    def obj_list_to_np_array_numeric(data: list[Person], attrs_list: list[str] = NUMERICAL_VARIABLES + CATEGORICAL_VARIABLES) -> np.array:\n",
    "        return DatasetManager.obj_list_to_np_array(data, attrs_list).astype(np.float64)\n",
    "\n",
    "    @staticmethod\n",
    "    def obj_list_to_np_array_category(data: list[Person], attrs_list: list[str] = NUMERICAL_VARIABLES + CATEGORICAL_VARIABLES) -> np.array:\n",
    "        data_pd = pd.DataFrame(DatasetManager.obj_list_to_np_array(data, attrs_list))\n",
    "        return np.vstack([pd.factorize(data_pd[col])[0] for col in data_pd.columns]).T\n",
    "\n",
    "    @staticmethod\n",
    "    def obj_list_to_np_array_category_binary(data: list[Person], attrs_list: list[str]) -> np.array:\n",
    "        data_pd = pd.DataFrame(DatasetManager.obj_list_to_np_array(data, attrs_list))\n",
    "        return pd.get_dummies(data_pd).to_numpy().astype(np.float64)\n",
    "\n",
    "    @staticmethod\n",
    "    def object_list_to_pd_dataframe_category(data: list[Person], attr: str) -> pd.Series:\n",
    "        return pd.DataFrame(DatasetManager.obj_list_to_np_array(data, [attr])).value_counts()\n",
    "\n",
    "    @staticmethod\n",
    "    def object_list_to_pd_dataframe_contingency_table(data: list[Person], lh_attr: str, rh_attr: str) -> pd.DataFrame:\n",
    "        data_pd = pd.DataFrame(DatasetManager.obj_list_to_np_array(data, [lh_attr, rh_attr]), columns=[lh_attr, rh_attr])\n",
    "        return pd.crosstab(data_pd[lh_attr], data_pd[rh_attr], margins=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_numerical_for_each_category(data: list[Person], numerical_attr: str, categorical_attr: str) -> list[tuple[np.array, str]]:\n",
    "\n",
    "        data_np = DatasetManager.obj_list_to_np_array(data, [numerical_attr, categorical_attr])\n",
    "        unique_categorical_values = np.unique(data_np[:, 1]).tolist()\n",
    "\n",
    "        return [(data_np[data_np[:, 1] == unique_val, 0].astype(np.float64), unique_val) for unique_val in unique_categorical_values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_manager = DatasetManager(\"data/ObesityDataSet.csv\")\n",
    "dataset_obj_list = dataset_manager.load_as_obj_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate analysis\n",
    "\n",
    "The following will be applied:\n",
    "1. central tendency\n",
    "1. spread\n",
    "1. distribution form (skewness, kurtosis)\n",
    "1. frequency of categorical data\n",
    "1. graphs\n",
    "    1. histograms\n",
    "    1. density\n",
    "    1. boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Central tendency\n",
    "\n",
    "Calculates mean, median and mode for each data series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_central_tendency_numerical(\n",
    "    np_dataset: np.array,\n",
    ") -> t.Tuple[float, float, float]:\n",
    "    mean = np.mean(np_dataset)\n",
    "    median = np.median(np_dataset)\n",
    "    mode = scpy_stats.mode(np_dataset).mode\n",
    "\n",
    "    return mean, median, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numerical_var in NUMERICAL_VARIABLES:\n",
    "    dataset_for_numerical_val = DatasetManager.obj_list_to_flat_np_array(\n",
    "        dataset_obj_list, [numerical_var]\n",
    "    )\n",
    "\n",
    "    mean, median, mode = calculate_central_tendency_numerical(dataset_for_numerical_val)\n",
    "\n",
    "    print(f\"On numerical var {numerical_var}\")\n",
    "    print(f\"Mean: {mean}\")\n",
    "    print(f\"Median: {median}\")\n",
    "    print(f\"Mode: {mode}\\n{['-' * 10]}\")\n",
    "    # MODE nu cred ca e si la variabile numerice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Spread\n",
    "\n",
    "Calculates the spread of data for each data series. Useful to know wether the data has a \"central tendency\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spread_numerical(np_dataset: np.array) -> t.Tuple[float, float, float]:\n",
    "    dataset_range = np.ptp(np_dataset)\n",
    "    dataset_variance = np.var(np_dataset)\n",
    "    dataset_standard_deviation = np.std(np_dataset)\n",
    "\n",
    "    return dataset_range, dataset_variance, dataset_standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numerical_var in numeric_variables:\n",
    "    dataset_for_numerical_val = DatasetManager.obj_list_to_flat_np_array(\n",
    "        dataset_obj_list, [numerical_var]\n",
    "    )\n",
    "    dataset_range, dataset_variance, dataset_standard_deviation = (\n",
    "        calculate_spread_numerical(dataset_for_numerical_val)\n",
    "    )\n",
    "\n",
    "    print(f\"On numerical var {numerical_var}\")\n",
    "    print(f\"Range: {dataset_range}\")\n",
    "    print(f\"Variance: {dataset_variance}\")\n",
    "    print(f\"Standard deviation: {dataset_standard_deviation}\")\n",
    "    print(f\"{['-' * 10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Skewness, kurtosis\n",
    "\n",
    "Calculates skewness and kurtosis of the dataset.\n",
    "\n",
    "Meaning for skewness:\n",
    "* Positively skewed (right-skewed):\n",
    "    * The distribution is positively skewed **if the distribution's tail on the right side is longer or \"fatter\" than the left side**. This means that there are more data points on the left side, and the distribution as a longer right tail.\n",
    "    * Values: `> 1`\n",
    "* Negatively skewed (left-skewed):\n",
    "    * The distribution is negatively skewed **if the distribution's tail on the left side is longer or \"fatter\" than the right side**. This means that there are more data points on the right side, and the distribution as a longer left tail.\n",
    "    * Values: `< -1`\n",
    "* Symmetric: \n",
    "    * If the distribution is _roughly_ the same on both sides, it is symmetric, and the skewness is close to 0.\n",
    "    * Values: `~ 0`\n",
    "\n",
    "Meaning of kurtosis:\n",
    "* Mesokurtic (Normal distribution):\n",
    "    * A distribution with kurtosis similar to that of a normal distribution\n",
    "    * Values: `~ 0`\n",
    "* Leptokurtic:\n",
    "    * A distribution with pisitive kurtosis, indicating heavier tails and a more peaked central region compared to a normal distribution\n",
    "    * Values: `> 1`\n",
    "* Platykurtic:\n",
    "    * A normal distribution with a negative kurtosis, indicating lighter tails and a flatter central region compared to a normal distribution\n",
    "    * Values: `< -1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_skewness_kurtosis_numerical(\n",
    "    np_dataset: np.array,\n",
    ") -> t.Tuple[float, float]:\n",
    "    dataset_skewness = scpy_stats.skew(np_dataset)\n",
    "    dataset_kurtosis = scpy_stats.kurtosis(np_dataset)\n",
    "\n",
    "    return dataset_skewness, dataset_kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numerical_var in numeric_variables:\n",
    "    dataset_for_numerical_val = DatasetManager.obj_list_to_flat_np_array(\n",
    "        dataset_obj_list, [numerical_var]\n",
    "    )\n",
    "    dataset_skewness, dataset_kurtosis = calculate_skewness_kurtosis_numerical(\n",
    "        dataset_for_numerical_val\n",
    "    )\n",
    "\n",
    "    print(f\"On numerical var {numerical_var}\")\n",
    "    print(f\"Skewness: {dataset_skewness}\")\n",
    "    print(f\"Kurtosis: {dataset_kurtosis}\")\n",
    "    print(f\"{['-' * 10]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Frequency of categorical data\n",
    "\n",
    "Here we count how often we see the categorical data in a data series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequency_of_data_categorical(dataset: t.List[str]) -> t.Dict[str, int]:\n",
    "    counts = {}\n",
    "\n",
    "    for entry in dataset:\n",
    "        if entry in counts:\n",
    "            counts[entry] += 1\n",
    "        else:\n",
    "            counts[entry] = 1\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categorical_var in categorical_values:\n",
    "    dataset_for_categorical_val = DatasetManager.obj_list_to_flat_list(\n",
    "        dataset_obj_list, [categorical_var]\n",
    "    )\n",
    "    dataset_frequency = calculate_frequency_of_data_categorical(\n",
    "        dataset_for_categorical_val\n",
    "    )\n",
    "\n",
    "    print(f\"On categorical var {categorical_var}\")\n",
    "\n",
    "    for entry in dataset_frequency:\n",
    "        print(f'Frequency of value \"{entry}\": {dataset_frequency[entry]}')\n",
    "\n",
    "    print(f\"{['-' * 10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Graphs\n",
    "\n",
    "Here we can find histograms, density charts and boxplots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Histograms\n",
    "\n",
    "Histograms plot how frequently we meet a data entry from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numerical_var in numeric_variables:\n",
    "    dataset_for_numerical_val = DatasetManager.obj_list_to_flat_np_array(\n",
    "        dataset_obj_list, [numerical_var]\n",
    "    )\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(\n",
    "        dataset_for_numerical_val,\n",
    "        bins=30,\n",
    "        color=\"lightblue\",\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.title(f'Histogram for numerical variable \"{numerical_var}\"')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categorical_var in categorical_values:\n",
    "    dataset_for_categorical_val = DatasetManager.obj_list_to_flat_list(\n",
    "        dataset_obj_list, [categorical_var]\n",
    "    )\n",
    "\n",
    "    dataset_frequency = calculate_frequency_of_data_categorical(\n",
    "        dataset_for_categorical_val\n",
    "    )\n",
    "    dataset_keys = [key for key in dataset_frequency]\n",
    "    dataset_values = [dataset_frequency[key] for key in dataset_frequency]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.bar(\n",
    "        dataset_keys, dataset_values, color=\"lightblue\", edgecolor=\"black\", alpha=0.7\n",
    "    )\n",
    "    plt.title(f'Histogram for categorical variable \"{categorical_var}\"')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Density charts\n",
    "\n",
    "Density charts plot how frequently we meet a data entry from the dataset and what distribution they follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numerical_var in numeric_variables:\n",
    "    dataset_for_numerical_val = DatasetManager.obj_list_to_flat_np_array(\n",
    "        dataset_obj_list, [numerical_var]\n",
    "    )\n",
    "\n",
    "    plt.figure()\n",
    "    sns.kdeplot(dataset_for_numerical_val, bw=0.1)\n",
    "    plt.hist(\n",
    "        dataset_for_numerical_val,\n",
    "        bins=30,\n",
    "        density=True,\n",
    "        color=\"lightblue\",\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.4,\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Values\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(f'Density Chart for \"{numerical_var}\"')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. Boxplots\n",
    "\n",
    "Boxplots charts show how the data \"behaves\":\n",
    "* min\n",
    "* max\n",
    "* quantiles\n",
    "* outliers\n",
    "* median\n",
    "* inter-quartile range (contains 50% of the data)\n",
    "* Skewness of data\n",
    "* Robustness to extreme values\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numerical_var in numeric_variables:\n",
    "    dataset_for_numerical_val = DatasetManager.obj_list_to_flat_np_array(\n",
    "        dataset_obj_list, [numerical_var]\n",
    "    )\n",
    "\n",
    "    plt.figure()\n",
    "    plt.boxplot(dataset_for_numerical_val, labels=[numerical_var])\n",
    "    plt.xlabel(\"Group\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.title(f'Boxplot for \"{numerical_var}\"')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Multivariate analysis\n",
    "\n",
    "The following will be applied:\n",
    "1. Find Pearson Correlation and Spearman (Rank) correlation\n",
    "1. Phi squared test, Fisher test and contingency tables\n",
    "1. T Test (Testul Mediilor), Z Test, ANOVA Test\n",
    "1. PCA in 2D si 3D; TSNE in 2d si 3D; Both using numerical + categorial\n",
    "1. Corrgrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. Find Pearson Correlation and Spearman (Rank) correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pearson_correlation: list[tuple[str, str, float]] = []\n",
    "rank_correlation: list[tuple[str, str, float]] = []\n",
    "\n",
    "for it in range(len(NUMERICAL_VARIABLES) - 1):\n",
    "    for jt in range(it + 1, len(NUMERICAL_VARIABLES)):\n",
    "        lh_var, rh_var = NUMERICAL_VARIABLES[it], NUMERICAL_VARIABLES[jt]\n",
    "\n",
    "        lh_dataset = DatasetManager.obj_list_to_np_array_numeric(dataset_obj_list, [lh_var]).reshape(-1)\n",
    "\n",
    "        rh_dataset = DatasetManager.obj_list_to_np_array_numeric(dataset_obj_list, [rh_var]).reshape(-1)\n",
    "\n",
    "        pearson_cr = scpy_stats.pearsonr(lh_dataset, rh_dataset).correlation\n",
    "        rank_cr = scpy_stats.spearmanr(lh_dataset, rh_dataset).correlation\n",
    "\n",
    "        pearson_correlation.append((lh_var, rh_var, pearson_cr))\n",
    "        rank_correlation.append((lh_var, rh_var, rank_cr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pearson_correlation = list(sorted(pearson_correlation, key=lambda x: x[2]))\n",
    "print(f\"Pearson Correlation\\n\\n\")\n",
    "for item in pearson_correlation:\n",
    "    print(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rank_correlation = list(sorted(rank_correlation, key=lambda x: x[2]))\n",
    "print(f\"Rank Correlation\\n\\n\")\n",
    "for item in rank_correlation:\n",
    "    print(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_numerical_correlations = pearson_correlation[:3] + pearson_correlation[-6:]\n",
    "print(best_numerical_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2. Phi squared test, Fisher test and contingency tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alfa = 0.05\n",
    "\n",
    "chi2_test: list[tuple[str, str, float]] = []\n",
    "fisher_test: list[tuple[str, str, float]] = []\n",
    "\n",
    "for it in range(len(CATEGORICAL_VARIABLES) - 1):\n",
    "    for jt in range(it + 1, len(CATEGORICAL_VARIABLES)):\n",
    "        lh_var, rh_var = CATEGORICAL_VARIABLES[it], CATEGORICAL_VARIABLES[jt]\n",
    "\n",
    "        dataset = DatasetManager.object_list_to_pd_dataframe_contingency_table(dataset_obj_list, lh_var, rh_var).to_numpy()\n",
    "\n",
    "        stat, p, degrees_of_freedom, expected_contingency = scpy_stats.chi2_contingency(dataset)\n",
    "\n",
    "        if p <= alfa:\n",
    "            print(f\"{(lh_var, rh_var)} DEPENDENTE CHI2={stat}\")\n",
    "            chi2_test.append((lh_var, rh_var, stat))\n",
    "        else:\n",
    "            print(f\"{(lh_var, rh_var)} INDEPENDENTE CHI2={stat}\")\n",
    "\n",
    "        if dataset.shape == (2, 2):\n",
    "            odds, p_value = scpy_stats.fisher_exact(dataset)\n",
    "            if p_value <= alfa:\n",
    "                fisher_test.append((lh_var, rh_var, odds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chi2_test = list(sorted(chi2_test, key=lambda x: x[2]))\n",
    "print(f\"CHI2 Test\\n\\n\")\n",
    "for item in chi2_test:\n",
    "    print(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_chi2_test = chi2_test[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for lh_var, rh_var, chi2_val in best_chi2_test[::-1]:\n",
    "    print(DatasetManager.object_list_to_pd_dataframe_contingency_table(dataset_obj_list, lh_var, rh_var))\n",
    "    print(\"\\n\" + \"\".join([\"-\"] * 10) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fisher_test = list(sorted(fisher_test, key=lambda x: x[2]))\n",
    "print(f\"Fisher Test\\n\\n\")\n",
    "for item in fisher_test:\n",
    "    print(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3. T Test (Testul Mediilor), Z Test, ANOVA Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alfa = 0.05\n",
    "\n",
    "t_test: list[tuple[str, str, float]] = []\n",
    "anova_test: list[tuple[str, str, float]] = []\n",
    "\n",
    "for it in range(len(NUMERICAL_VARIABLES)):\n",
    "    for jt in range(len(CATEGORICAL_VARIABLES)):\n",
    "        lh_var, rh_var = NUMERICAL_VARIABLES[it], CATEGORICAL_VARIABLES[jt]\n",
    "\n",
    "        numerical_for_each_category = DatasetManager.get_numerical_for_each_category(dataset_obj_list, lh_var, rh_var)\n",
    "\n",
    "        if len(numerical_for_each_category) == 2:\n",
    "            lh_numeric_data, rh_numeric_data = numerical_for_each_category[0][0], numerical_for_each_category[1][0]\n",
    "\n",
    "            statistic, p_value = scpy_stats.ttest_ind(lh_numeric_data, rh_numeric_data)\n",
    "\n",
    "            if p_value <= alfa:\n",
    "                print(f\"Found {(lh_var, rh_var)} TO BE correlated with T Test={statistic}\")\n",
    "                t_test.append((lh_var, rh_var, statistic))\n",
    "            else:\n",
    "                print(f\"Found {(lh_var, rh_var)} NOT TO BE correlated with T Test={statistic}\")\n",
    "        else:\n",
    "            statistic, p_value = scpy_stats.f_oneway(*[part[0] for part in numerical_for_each_category])\n",
    "\n",
    "            if p_value <= alfa:\n",
    "                print(f\"Found {(lh_var, rh_var)} TO BE correlated with ANOVA Test={statistic}\")\n",
    "                anova_test.append((lh_var, rh_var, statistic))\n",
    "            else:\n",
    "                print(f\"Found {(lh_var, rh_var)} NOT TO BE correlated with ANOVA Test={statistic}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_test = list(sorted(t_test, key=lambda x: x[2]))\n",
    "print(f\"Testul mediilor (T-Test)\\n\\n\")\n",
    "for item in t_test:\n",
    "    print(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anova_test = list(sorted(anova_test, key=lambda x: x[2]))\n",
    "print(f\"Testul ANOVA\\n\\n\")\n",
    "for item in anova_test:\n",
    "    print(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_t_test = t_test[:8] + t_test[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_anova_test = anova_test[-14:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4. PCA in 2D si 3D; TSNE in 2d si 3D; Both using numerical + categorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_dataset = DatasetManager.obj_list_to_np_array_numeric(dataset_obj_list, NUMERICAL_VARIABLES)\n",
    "#numeric_dataset = StandardScaler().fit_transform(numeric_dataset)\n",
    "\n",
    "categorical_to_binary_dataset = DatasetManager.obj_list_to_np_array_category_binary(dataset_obj_list, CATEGORICAL_VARIABLES_NO_LABEL)\n",
    "numerical_categorical_dataset = np.hstack((numeric_dataset, categorical_to_binary_dataset))\n",
    "#numerical_categorical_dataset = StandardScaler().fit_transform(numerical_categorical_dataset)\n",
    "\n",
    "label_dataset = DatasetManager.obj_list_to_np_array(dataset_obj_list, [LABEL_VARIABLE])\n",
    "label_dataset, label_indexes = pd.factorize(pd.DataFrame(label_dataset)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numerical_transformed_2d = PCA(n_components=2).fit_transform(numeric_dataset)\n",
    "numerical_transformed_3d = PCA(n_components=3).fit_transform(numeric_dataset)\n",
    "\n",
    "numerical_categorial_transformed_2d = PCA(n_components=2).fit_transform(numerical_categorical_dataset)\n",
    "numerical_categorial_transformed_3d = PCA(n_components=3).fit_transform(numerical_categorical_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(numerical_transformed_2d[:, 0], numerical_transformed_2d[:, 1], c=label_dataset, label=label_dataset)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(numerical_categorial_transformed_2d[:, 0], numerical_categorial_transformed_2d[:, 1], c=label_dataset)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5. Corrgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
