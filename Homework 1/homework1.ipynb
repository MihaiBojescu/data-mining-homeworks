{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import typing as t\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import itertools\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    Gender: str\n",
    "    Age: int\n",
    "    Height: float\n",
    "    Weight: float\n",
    "    family_history_with_overweight: str\n",
    "    FAVC: str\n",
    "    FCVC: int\n",
    "    NCP: int\n",
    "    CAEC: str\n",
    "    SMOKE: str\n",
    "    CH2O: int\n",
    "    SCC: str\n",
    "    FAF: str\n",
    "    TUE: int\n",
    "    CALC: str\n",
    "    MTRANS: str\n",
    "    NObeyesdad: str\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        Gender: str,\n",
    "        Age: int,\n",
    "        Height: float,\n",
    "        Weight: float,\n",
    "        family_history_with_overweight: str,\n",
    "        FAVC: str,\n",
    "        FCVC: int,\n",
    "        NCP: int,\n",
    "        CAEC: str,\n",
    "        SMOKE: str,\n",
    "        CH2O: int,\n",
    "        SCC: str,\n",
    "        FAF: int,\n",
    "        TUE: int,\n",
    "        CALC: str,\n",
    "        MTRANS: str,\n",
    "        NObeyesdad: str,\n",
    "    ):\n",
    "        self.Gender = Gender\n",
    "        self.Age = Age\n",
    "        self.Height = Height\n",
    "        self.Weight = Weight\n",
    "        self.family_history_with_overweight = family_history_with_overweight\n",
    "        self.FAVC = FAVC\n",
    "        self.FCVC = FCVC\n",
    "        self.NCP = NCP\n",
    "        self.CAEC = CAEC\n",
    "        self.SMOKE = SMOKE\n",
    "        self.CH2O = CH2O\n",
    "        self.SCC = SCC\n",
    "        self.FAF = FAF\n",
    "        self.TUE = TUE\n",
    "        self.CALC = CALC\n",
    "        self.MTRANS = MTRANS\n",
    "        self.NObeyesdad = NObeyesdad\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\n",
    "            \"{\"\n",
    "            + f'\"Gender\": \"{self.Gender}\",'\n",
    "            + f'\"Age\": {self.Age},'\n",
    "            + f'\"Height\": {self.Height},'\n",
    "            + f'\"Weight\": {self.Weight},'\n",
    "            + f'\"family_history_with_overweight\": \"{self.family_history_with_overweight}\",'\n",
    "            + f'\"FAVC\": \"{self.FAVC}\",'\n",
    "            + f'\"FCVC\": {self.FCVC},'\n",
    "            + f'\"NCP\": {self.NCP},'\n",
    "            + f'\"CAEC\": \"{self.CAEC}\",'\n",
    "            + f'\"SMOKE\": \"{self.SMOKE}\",'\n",
    "            + f'\"CH2O\": {self.CH2O},'\n",
    "            + f'\"SCC\": {self.SCC},'\n",
    "            + f'\"FAF\": \"{self.FAF}\",'\n",
    "            + f'\"TUE\": {self.TUE},'\n",
    "            + f'\"CALC\": \"{self.CALC}\",'\n",
    "            + f'\"MTRANS\": \"{self.MTRANS}\",'\n",
    "            + f'\"NObeyesdad\": \"{self.NObeyesdad}\"'\n",
    "            + \"}\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return 17\n",
    "\n",
    "    __repr__ = __str__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_variables = [\"Age\", \"Height\", \"Weight\", \"FCVC\", \"NCP\", \"CH2O\", \"FAF\", \"TUE\"]\n",
    "categorical_values = [\n",
    "    \"FAVC\",\n",
    "    \"CAEC\",\n",
    "    \"CALC\",\n",
    "    \"SCC\",\n",
    "    \"MTRANS\",\n",
    "    \"Gender\",\n",
    "    \"family_history_with_overweight\",\n",
    "    \"SMOKE\",\n",
    "    \"NObeyesdad\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DatasetManager:\n",
    "    def __init__(self, path_to_csv: str):\n",
    "        self.path_to_csv = path_to_csv\n",
    "\n",
    "    def load_as_obj_list(self) -> list[Person]:\n",
    "        with open(self.path_to_csv) as csv_file:\n",
    "            csv_reader = csv.DictReader(csv_file)\n",
    "            return [Person(**row) for row in csv_reader]\n",
    "\n",
    "    @staticmethod\n",
    "    def obj_list_to_np_array(\n",
    "        data: list[Person],\n",
    "        attrs_list: list[str] = numeric_variables + categorical_values,\n",
    "    ) -> t.List[npt.NDArray[np.float32]]:\n",
    "        return [\n",
    "            np.array([np.float32(getattr(entry, field)) for entry in data])\n",
    "            for field in attrs_list\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def obj_list_to_flat_np_array(\n",
    "        data: list[Person],\n",
    "        attrs_list: list[str] = numeric_variables + categorical_values,\n",
    "    ) -> npt.NDArray[np.float32]:\n",
    "        return np.array(\n",
    "            [\n",
    "                np.float32(getattr(entry, field))\n",
    "                for entry in data\n",
    "                for field in attrs_list\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def obj_list_to_list(\n",
    "        data: t.List[Person], attrs_list: t.List[str] = categorical_values\n",
    "    ) -> t.List[t.List[str]]:\n",
    "        return [[getattr(entry, field) for field in attrs_list] for entry in data]\n",
    "\n",
    "    @staticmethod\n",
    "    def obj_list_to_flat_list(\n",
    "        data: t.List[Person], attrs_list: t.List[str] = categorical_values\n",
    "    ) -> t.List[str]:\n",
    "        return [getattr(entry, field) for field in attrs_list for entry in data]\n",
    "\n",
    "    @staticmethod\n",
    "    def make_combinations(\n",
    "        attrs_list: t.List[str], k: int = 2\n",
    "    ) -> t.List[t.Tuple[str, ...]]:\n",
    "        return [subset for subset in itertools.combinations(attrs_list, k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_manager = DatasetManager(\"data/ObesityDataSet.csv\")\n",
    "dataset_obj_list = dataset_manager.load_as_obj_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate analysis\n",
    "\n",
    "The following will be applied:\n",
    "1. central tendency\n",
    "1. spread\n",
    "1. distribution form (skewness, kurtosis)\n",
    "1. frequency of categorical data\n",
    "1. graphs\n",
    "    1. histograms\n",
    "    1. density\n",
    "    1. boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Central tendency\n",
    "\n",
    "Calculates mean, median and mode for each data series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_central_tendency_numerical(\n",
    "    np_dataset: np.array,\n",
    ") -> t.Tuple[float, float, float]:\n",
    "    mean = np.mean(np_dataset)\n",
    "    median = np.median(np_dataset)\n",
    "    mode = stats.mode(np_dataset).mode\n",
    "\n",
    "    return mean, median, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numerical_var in numeric_variables:\n",
    "    dataset_for_numerical_val = DatasetManager.obj_list_to_flat_np_array(\n",
    "        dataset_obj_list, [numerical_var]\n",
    "    )\n",
    "\n",
    "    mean, median, mode = calculate_central_tendency_numerical(dataset_for_numerical_val)\n",
    "\n",
    "    print(f\"On numerical var {numerical_var}\")\n",
    "    print(f\"Mean: {mean}\")\n",
    "    print(f\"Median: {median}\")\n",
    "    print(f\"Mode: {mode}\\n{['-' * 10]}\")\n",
    "    # MODE nu cred ca e si la variabile numerice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Spread\n",
    "\n",
    "Calculates the spread of data for each data series. Useful to know wether the data has a \"central tendency\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spread_numerical(np_dataset: np.array) -> t.Tuple[float, float, float]:\n",
    "    dataset_range = np.ptp(np_dataset)\n",
    "    dataset_variance = np.var(np_dataset)\n",
    "    dataset_standard_deviation = np.std(np_dataset)\n",
    "\n",
    "    return dataset_range, dataset_variance, dataset_standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numerical_var in numeric_variables:\n",
    "    dataset_for_numerical_val = DatasetManager.obj_list_to_flat_np_array(\n",
    "        dataset_obj_list, [numerical_var]\n",
    "    )\n",
    "    dataset_range, dataset_variance, dataset_standard_deviation = (\n",
    "        calculate_spread_numerical(dataset_for_numerical_val)\n",
    "    )\n",
    "\n",
    "    print(f\"On numerical var {numerical_var}\")\n",
    "    print(f\"Range: {dataset_range}\")\n",
    "    print(f\"Variance: {dataset_variance}\")\n",
    "    print(f\"Standard deviation: {dataset_standard_deviation}\")\n",
    "    print(f\"{['-' * 10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Skewness, kurtosis\n",
    "\n",
    "Calculates skewness and kurtosis of the dataset.\n",
    "\n",
    "Meaning for skewness:\n",
    "* Positively skewed (right-skewed):\n",
    "    * The distribution is positively skewed **if the distribution's tail on the right side is longer or \"fatter\" than the left side**. This means that there are more data points on the left side, and the distribution as a longer right tail.\n",
    "    * Values: `> 1`\n",
    "* Negatively skewed (left-skewed):\n",
    "    * The distribution is negatively skewed **if the distribution's tail on the left side is longer or \"fatter\" than the right side**. This means that there are more data points on the right side, and the distribution as a longer left tail.\n",
    "    * Values: `< -1`\n",
    "* Symmetric: \n",
    "    * If the distribution is _roughly_ the same on both sides, it is symmetric, and the skewness is close to 0.\n",
    "    * Values: `~ 0`\n",
    "\n",
    "Meaning of kurtosis:\n",
    "* Mesokurtic (Normal distribution):\n",
    "    * A distribution with kurtosis similar to that of a normal distribution\n",
    "    * Values: `~ 0`\n",
    "* Leptokurtic:\n",
    "    * A distribution with pisitive kurtosis, indicating heavier tails and a more peaked central region compared to a normal distribution\n",
    "    * Values: `> 1`\n",
    "* Platykurtic:\n",
    "    * A normal distribution with a negative kurtosis, indicating lighter tails and a flatter central region compared to a normal distribution\n",
    "    * Values: `< -1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_skewness_kurtosis_numerical(\n",
    "    np_dataset: np.array,\n",
    ") -> t.Tuple[float, float]:\n",
    "    dataset_skewness = stats.skew(np_dataset)\n",
    "    dataset_kurtosis = stats.kurtosis(np_dataset)\n",
    "\n",
    "    return dataset_skewness, dataset_kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numerical_var in numeric_variables:\n",
    "    dataset_for_numerical_val = DatasetManager.obj_list_to_flat_np_array(\n",
    "        dataset_obj_list, [numerical_var]\n",
    "    )\n",
    "    dataset_skewness, dataset_kurtosis = calculate_skewness_kurtosis_numerical(\n",
    "        dataset_for_numerical_val\n",
    "    )\n",
    "\n",
    "    print(f\"On numerical var {numerical_var}\")\n",
    "    print(f\"Skewness: {dataset_skewness}\")\n",
    "    print(f\"Kurtosis: {dataset_kurtosis}\")\n",
    "    print(f\"{['-' * 10]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Frequency of categorical data\n",
    "\n",
    "Here we count how often we see the categorical data in a data series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequency_of_data_categorical(dataset: t.List[str]) -> t.Dict[str, int]:\n",
    "    counts = {}\n",
    "\n",
    "    for entry in dataset:\n",
    "        if entry in counts:\n",
    "            counts[entry] += 1\n",
    "        else:\n",
    "            counts[entry] = 1\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categorical_var in categorical_values:\n",
    "    dataset_for_categorical_val = DatasetManager.obj_list_to_flat_list(\n",
    "        dataset_obj_list, [categorical_var]\n",
    "    )\n",
    "    dataset_frequency = calculate_frequency_of_data_categorical(\n",
    "        dataset_for_categorical_val\n",
    "    )\n",
    "\n",
    "    print(f\"On categorical var {categorical_var}\")\n",
    "\n",
    "    for entry in dataset_frequency:\n",
    "        print(f'Frequency of value \"{entry}\": {dataset_frequency[entry]}')\n",
    "\n",
    "    print(f\"{['-' * 10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Graphs\n",
    "\n",
    "Here we can find histograms, density charts and boxplots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Histograms\n",
    "\n",
    "Histograms plot how frequently we meet a data entry from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numerical_var in numeric_variables:\n",
    "    dataset_for_numerical_val = DatasetManager.obj_list_to_flat_np_array(\n",
    "        dataset_obj_list, [numerical_var]\n",
    "    )\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(\n",
    "        dataset_for_numerical_val,\n",
    "        bins=30,\n",
    "        color=\"lightblue\",\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.title(f'Histogram for numerical variable \"{numerical_var}\"')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categorical_var in categorical_values:\n",
    "    dataset_for_categorical_val = DatasetManager.obj_list_to_flat_list(\n",
    "        dataset_obj_list, [categorical_var]\n",
    "    )\n",
    "\n",
    "    dataset_frequency = calculate_frequency_of_data_categorical(\n",
    "        dataset_for_categorical_val\n",
    "    )\n",
    "    dataset_keys = [key for key in dataset_frequency]\n",
    "    dataset_values = [dataset_frequency[key] for key in dataset_frequency]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.bar(\n",
    "        dataset_keys, dataset_values, color=\"lightblue\", edgecolor=\"black\", alpha=0.7\n",
    "    )\n",
    "    plt.title(f'Histogram for categorical variable \"{categorical_var}\"')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Density charts\n",
    "\n",
    "Density charts plot how frequently we meet a data entry from the dataset and what distribution they follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numerical_var in numeric_variables:\n",
    "    dataset_for_numerical_val = DatasetManager.obj_list_to_flat_np_array(\n",
    "        dataset_obj_list, [numerical_var]\n",
    "    )\n",
    "\n",
    "    plt.figure()\n",
    "    sns.kdeplot(dataset_for_numerical_val, bw=0.1)\n",
    "    plt.hist(\n",
    "        dataset_for_numerical_val,\n",
    "        bins=30,\n",
    "        density=True,\n",
    "        color=\"lightblue\",\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.4,\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Values\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(f'Density Chart for \"{numerical_var}\"')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. Boxplots\n",
    "\n",
    "Boxplots charts show how the data \"behaves\":\n",
    "* min\n",
    "* max\n",
    "* quantiles\n",
    "* outliers\n",
    "* median\n",
    "* inter-quartile range (contains 50% of the data)\n",
    "* Skewness of data\n",
    "* Robustness to extreme values\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numerical_var in numeric_variables:\n",
    "    dataset_for_numerical_val = DatasetManager.obj_list_to_flat_np_array(\n",
    "        dataset_obj_list, [numerical_var]\n",
    "    )\n",
    "\n",
    "    plt.figure()\n",
    "    plt.boxplot(dataset_for_numerical_val, labels=[numerical_var])\n",
    "    plt.xlabel(\"Group\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.title(f'Boxplot for \"{numerical_var}\"')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate/multivariate analysis\n",
    "\n",
    "The following will be applied:\n",
    "1. correlations between data series\n",
    "1. independence test\n",
    "1. test of means between populations\n",
    "1. some visualisations:\n",
    "    1. scatter-plots\n",
    "    1. 3D graphs\n",
    "    1. scatter-plots on main components\n",
    "    1. non-linear mappings in 2d space: Sammon, t-SNE, uMap\n",
    "    1. \"projection pursuit\" methodologies\n",
    "    1. conditional boxplots\n",
    "    1. overlaid histograms\n",
    "    1. corrgrams "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Correlations between data series\n",
    "\n",
    "**TODO**: Maybe add for categorical data too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On numerical vars \"Age\" - \"Height\"\n",
      "Correlation coefficient: -0.02595814550352338\n",
      "['----------']\n",
      "On numerical vars \"Age\" - \"Weight\"\n",
      "Correlation coefficient: 0.20256010869202493\n",
      "['----------']\n",
      "On numerical vars \"Age\" - \"FCVC\"\n",
      "Correlation coefficient: 0.016290887845249083\n",
      "['----------']\n",
      "On numerical vars \"Age\" - \"NCP\"\n",
      "Correlation coefficient: -0.043943723836591404\n",
      "['----------']\n",
      "On numerical vars \"Age\" - \"CH2O\"\n",
      "Correlation coefficient: -0.045303855685585266\n",
      "['----------']\n",
      "On numerical vars \"Age\" - \"FAF\"\n",
      "Correlation coefficient: -0.14493832659416925\n",
      "['----------']\n",
      "On numerical vars \"Age\" - \"TUE\"\n",
      "Correlation coefficient: -0.29693059440346053\n",
      "['----------']\n",
      "On numerical vars \"Height\" - \"Weight\"\n",
      "Correlation coefficient: 0.46313611109946323\n",
      "['----------']\n",
      "On numerical vars \"Height\" - \"FCVC\"\n",
      "Correlation coefficient: -0.03812106813312755\n",
      "['----------']\n",
      "On numerical vars \"Height\" - \"NCP\"\n",
      "Correlation coefficient: 0.2436717259084431\n",
      "['----------']\n",
      "On numerical vars \"Height\" - \"CH2O\"\n",
      "Correlation coefficient: 0.2133759162710386\n",
      "['----------']\n",
      "On numerical vars \"Height\" - \"FAF\"\n",
      "Correlation coefficient: 0.29470899063282063\n",
      "['----------']\n",
      "On numerical vars \"Height\" - \"TUE\"\n",
      "Correlation coefficient: 0.05191167316880238\n",
      "['----------']\n",
      "On numerical vars \"Weight\" - \"FCVC\"\n",
      "Correlation coefficient: 0.21612470586683277\n",
      "['----------']\n",
      "On numerical vars \"Weight\" - \"NCP\"\n",
      "Correlation coefficient: 0.10746898695558375\n",
      "['----------']\n",
      "On numerical vars \"Weight\" - \"CH2O\"\n",
      "Correlation coefficient: 0.2005753846440006\n",
      "['----------']\n",
      "On numerical vars \"Weight\" - \"FAF\"\n",
      "Correlation coefficient: -0.05143626705235206\n",
      "['----------']\n",
      "On numerical vars \"Weight\" - \"TUE\"\n",
      "Correlation coefficient: -0.0715613577251518\n",
      "['----------']\n",
      "On numerical vars \"FCVC\" - \"NCP\"\n",
      "Correlation coefficient: 0.04221629559667975\n",
      "['----------']\n",
      "On numerical vars \"FCVC\" - \"CH2O\"\n",
      "Correlation coefficient: 0.06846146823337441\n",
      "['----------']\n",
      "On numerical vars \"FCVC\" - \"FAF\"\n",
      "Correlation coefficient: 0.019939398251012964\n",
      "['----------']\n",
      "On numerical vars \"FCVC\" - \"TUE\"\n",
      "Correlation coefficient: -0.10113484670537422\n",
      "['----------']\n",
      "On numerical vars \"NCP\" - \"CH2O\"\n",
      "Correlation coefficient: 0.05708799161833937\n",
      "['----------']\n",
      "On numerical vars \"NCP\" - \"FAF\"\n",
      "Correlation coefficient: 0.1295043056213303\n",
      "['----------']\n",
      "On numerical vars \"NCP\" - \"TUE\"\n",
      "Correlation coefficient: 0.036325570455280905\n",
      "['----------']\n",
      "On numerical vars \"CH2O\" - \"FAF\"\n",
      "Correlation coefficient: 0.16723649060307605\n",
      "['----------']\n",
      "On numerical vars \"CH2O\" - \"TUE\"\n",
      "Correlation coefficient: 0.011965335939089375\n",
      "['----------']\n",
      "On numerical vars \"FAF\" - \"TUE\"\n",
      "Correlation coefficient: 0.05856206586476506\n",
      "['----------']\n"
     ]
    }
   ],
   "source": [
    "for attribute_a, attribute_b in DatasetManager.make_combinations(numeric_variables):\n",
    "    [attribute_a_data, attribute_b_data] = DatasetManager.obj_list_to_np_array(\n",
    "        dataset_obj_list, [attribute_a, attribute_b]\n",
    "    )\n",
    "\n",
    "    correlation_matrix = np.corrcoef(attribute_a_data, attribute_b_data)\n",
    "    correlation_coefficient = correlation_matrix[0, 1]\n",
    "\n",
    "    print(f'On numerical vars \"{attribute_a}\" - \"{attribute_b}\"')\n",
    "    print(f\"Correlation coefficient: {correlation_coefficient}\")\n",
    "    print(f\"{['-' * 10]}\")\n",
    "\n",
    "dataset = DatasetManager.obj_list_to_np_array(dataset_obj_list, numeric_variables)\n",
    "correlation_matrix = np.corrcoef(dataset)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(correlation_matrix, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Correlation coefficient\")\n",
    "plt.title(f'Correlation matrix heatmap, numerical data')\n",
    "plt.xticks(range(len(correlation_matrix)), numeric_variables, rotation=45, ha='right')\n",
    "plt.yticks(range(len(correlation_matrix)), numeric_variables)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Independence test between data series\n",
    "\n",
    "**TODO**: Maybe add for categorical data too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_contingency_table_numerical(\n",
    "    np_dataset_a: npt.NDArray[np.float32], np_dataset_b: npt.NDArray[np.float32]\n",
    ") -> npt.NDArray[np.float32]:\n",
    "\n",
    "    categories_a = np.unique(np_dataset_a)\n",
    "    categories_b = np.unique(np_dataset_b)\n",
    "\n",
    "    contingency_table = np.zeros((len(categories_a), len(categories_b)), dtype=int)\n",
    "\n",
    "    for i, cat1 in enumerate(categories_a):\n",
    "        for j, cat2 in enumerate(categories_b):\n",
    "            contingency_table[i, j] = np.sum(\n",
    "                (attribute_a_data == cat1) & (attribute_b_data == cat2)\n",
    "            )\n",
    "\n",
    "    return contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Might need revising? I don't think it does what it should do... Last execution took 2m52s900ms before I force-stopped it.\n",
    "\n",
    "for attribute_a, attribute_b in DatasetManager.make_combinations(numeric_variables):\n",
    "    [attribute_a_data, attribute_b_data] = DatasetManager.obj_list_to_np_array(\n",
    "        dataset_obj_list, [attribute_a, attribute_b]\n",
    "    )\n",
    "    contingency_table = calculate_contingency_table_numerical(\n",
    "        attribute_a_data, attribute_b_data\n",
    "    )\n",
    "\n",
    "    chi2_stat, p_value, degrees_of_freedom, expected_frequencies = (\n",
    "        stats.chi2_contingency(contingency_table)\n",
    "    )\n",
    "\n",
    "    print(f'On numerical vars \"{attribute_a}\" - \"{attribute_b}\"')\n",
    "    print(f\"Chi-squared statistic: {chi2_stat}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "    print(f\"Degrees of freedom: {degrees_of_freedom}\")\n",
    "    print(f\"Expected_frequencies: {expected_frequencies}\")\n",
    "    print(f\"{['-' * 10]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
