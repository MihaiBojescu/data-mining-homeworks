{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Homework 2 - association rules\n",
    "\n",
    "In this homework we will perform association between data series in the obesity dataset. For this notebook we will use the following formulas:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    support(X) &= P(X) \\\\\n",
    "            &= \\frac{\\text{number of instances containing X in the dataset}}{\\text{total number of items in the dataset}} \\\\\n",
    "    \\\\\n",
    "    support(X \\rightarrow Y) &= P(X \\cap Y) \\\\\n",
    "                            &= support(X \\cup Y) \\\\\n",
    "                            &= \\frac{\\text{number of instances containing both X and Y in the dataset}}{\\text{total number of items in the dataset}} \\\\\n",
    "    \\\\\n",
    "    confidence(X \\rightarrow Y) &= P(Y|X) = \\frac{P(X \\cap Y)}{P(X)} \\\\\n",
    "                                &= \\frac{support(X \\cup Y)}{support(X)} \\\\\n",
    "    \\\\\n",
    "    lift(X \\rightarrow Y) &= \\frac{P(X \\cap Y)}{P(X) \\cdot P(Y)} \\\\\n",
    "                          &= \\frac{support(X \\cup Y)}{support(X) \\cdot support(Y)} \\\\\n",
    "    \\\\\n",
    "    conviction(X \\rightarrow Y) &= \\frac{1 - P(Y)}{1 - P(Y|X)} = \\frac{1 - P(Y)}{1 - \\frac{P(X \\cap Y)}{P(X)}} \\\\\n",
    "                                &= \\frac{1 - support(Y)}{1 - confidence(X \\rightarrow Y)} \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We will use the Apriori and ECLAT algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "Using the Apriori algorithm, we gathered the following conclusions:\n",
    "- for numerical - numerical attribute analysis:\n",
    "  - With over average confidence (`0.67`) and low support (`0.27`), we can state that people that **consume many vegetables per day** also **consume more meals**\n",
    "- for categorial - categorial attribute analysis:\n",
    "  - Majority of the surveyed population **does not smoke** (support `0.97`, confidence `0.97`)\n",
    "  - Majority of the surveyed population **does not perform calories monitoring** (support `0.95`, confidence `0.95`)\n",
    "  - A good part of the surveyed population that **presents an overweight family member** reported **frequent consumption of high-caloric food** (support `0.74`, confidence `0.91`)\n",
    "- for categorial + numerical - categorial + numerical attribute analysis:\n",
    "  - With rather high confidence (`0.90`), but rather low support (`0.40`), people that **eat 3 meals per day**, **sometimes eat outside of meal hours** and **don't perform calorie monitoring** have **an overweight family member**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### General dependencies\n",
    "\n",
    "Imports for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import platform\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    os.environ['R_HOME'] = 'C:\\Program Files\\R\\R-4.3.3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import typing as t\n",
    "import csv\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import HTML, IFrame\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import arulespy.arules as arules\n",
    "import arulespy.arulesViz as arulesviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import rpy2.robjects.packages as packages\n",
    "import rpy2.robjects.lib.ggplot2 as gp\n",
    "from rpy2.ipython.ggplot import image_png\n",
    "from arulespy.arulesViz import plot, inspectDT\n",
    "from catscatter import catscatter\n",
    "\n",
    "htmlwidgets = packages.importr(\"htmlwidgets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Dataset-specific dependencies\n",
    "\n",
    "Dataset manager, known labels, known outputs for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "LABEL_VARIABLE = \"NObeyesdad\"\n",
    "NUMERICAL_VARIABLES = [\"Age\", \"Height\", \"Weight\", \"FCVC\", \"NCP\", \"CH2O\", \"FAF\", \"TUE\"]\n",
    "CATEGORICAL_VARIABLES_NO_LABEL = [\n",
    "    \"FAVC\",\n",
    "    \"CAEC\",\n",
    "    \"CALC\",\n",
    "    \"SCC\",\n",
    "    \"MTRANS\",\n",
    "    \"Gender\",\n",
    "    \"family_history_with_overweight\",\n",
    "    \"SMOKE\",\n",
    "]\n",
    "CATEGORICAL_VARIABLES = [\n",
    "    *CATEGORICAL_VARIABLES_NO_LABEL,\n",
    "    LABEL_VARIABLE,\n",
    "]\n",
    "ALL_VARIABLES_NO_LABEL = [*NUMERICAL_VARIABLES, *CATEGORICAL_VARIABLES_NO_LABEL]\n",
    "ALL_VARIABLES = [*NUMERICAL_VARIABLES, *CATEGORICAL_VARIABLES]\n",
    "LABEL_DICTIONARY = {\n",
    "    \"Age\": \"Age\",\n",
    "    \"Height\": \"Height (cm)\",\n",
    "    \"Weight\": \"Weight (kg)\",\n",
    "    \"FCVC\": \" Frequency of consumption of vegetables (times per day)\",\n",
    "    \"NCP\": \"Number of main meals\",\n",
    "    \"CH2O\": \"Consumption of water daily (Liters)\",\n",
    "    \"FAF\": \"Physical activity frequency (times per day)\",\n",
    "    \"TUE\": \"Time using technology devices (hours)\",\n",
    "    \"FAVC\": \"Frequent consumption of high caloric food\",\n",
    "    \"CAEC\": \"Consumption of food between meals\",\n",
    "    \"CALC\": \"Consumption of alcohol\",\n",
    "    \"SCC\": \"Calories consumption monitoring\",\n",
    "    \"MTRANS\": \"Transportation used\",\n",
    "    \"Gender\": \"Gender\",\n",
    "    \"family_history_with_overweight\": \"Family member suffered or suffers from overweight\",\n",
    "    \"SMOKE\": \"Smoker or not\",\n",
    "    \"NObeyesdad\": \"Obesity level\",\n",
    "}\n",
    "\n",
    "T = t.TypeVar(\"T\")\n",
    "\n",
    "\n",
    "class Person:\n",
    "    Gender: str\n",
    "    Age: np.int32\n",
    "    Height: np.float32\n",
    "    Weight: np.float32\n",
    "    family_history_with_overweight: str\n",
    "    FAVC: str\n",
    "    FCVC: np.float32\n",
    "    NCP: np.float32\n",
    "    CAEC: str\n",
    "    SMOKE: str\n",
    "    CH2O: np.float32\n",
    "    SCC: str\n",
    "    FAF: np.float32\n",
    "    TUE: np.float32\n",
    "    CALC: str\n",
    "    MTRANS: str\n",
    "    NObeyesdad: str\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        Gender: str,\n",
    "        Age: str,\n",
    "        Height: str,\n",
    "        Weight: str,\n",
    "        family_history_with_overweight: str,\n",
    "        FAVC: str,\n",
    "        FCVC: str,\n",
    "        NCP: str,\n",
    "        CAEC: str,\n",
    "        SMOKE: str,\n",
    "        CH2O: str,\n",
    "        SCC: str,\n",
    "        FAF: str,\n",
    "        TUE: str,\n",
    "        CALC: str,\n",
    "        MTRANS: str,\n",
    "        NObeyesdad: str,\n",
    "    ):\n",
    "        self.Gender = Gender\n",
    "        self.Age = np.float32(Age)\n",
    "        self.Height = np.float32(Height)\n",
    "        self.Weight = np.float32(Weight)\n",
    "        self.family_history_with_overweight = family_history_with_overweight\n",
    "        self.FAVC = FAVC\n",
    "        self.FCVC = np.float32(FCVC)\n",
    "        self.NCP = np.float32(NCP)\n",
    "        self.CAEC = CAEC\n",
    "        self.SMOKE = SMOKE\n",
    "        self.CH2O = np.float32(CH2O)\n",
    "        self.SCC = SCC\n",
    "        self.FAF = np.float32(FAF)\n",
    "        self.TUE = np.float32(TUE)\n",
    "        self.CALC = CALC\n",
    "        self.MTRANS = MTRANS\n",
    "        self.NObeyesdad = NObeyesdad\n",
    "\n",
    "    def __str__(self):\n",
    "        return vars(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(vars(self))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return vars(self)\n",
    "\n",
    "\n",
    "class DatasetManager:\n",
    "    def __init__(self, path_to_csv: str):\n",
    "        self.path_to_csv = path_to_csv\n",
    "\n",
    "    def load_as_obj_list(self) -> list[Person]:\n",
    "        with open(self.path_to_csv) as csv_file:\n",
    "            csv_reader = csv.DictReader(csv_file)\n",
    "            return [Person(**row) for row in csv_reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataset_manager = DatasetManager(\"data/ObesityDataSet.csv\")\n",
    "dataset_obj_list = dataset_manager.load_as_obj_list()\n",
    "dataset_dataframe = pd.DataFrame.from_records(\n",
    "    data=[vars(entry) for entry in dataset_obj_list]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Categorial data utility functions\n",
    "\n",
    "Here we add utility functions (if any) for the categorial data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: add if any are found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Continuous data utility functions\n",
    "\n",
    "Here we add utility functions (if any) for the continuous data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_np_bins_and_labels(bins: list[tuple[float, float]]) -> tuple[np.array, list[str]]:\n",
    "    return np.array(np.array(bins).T[0].tolist() + [bins[-1][1]]).astype(np.float32), [f\"({lh}, {rh}]\" for lh, rh in bins]\n",
    "\n",
    "\n",
    "predifined_bins = {\n",
    "    \"Age\": get_np_bins_and_labels([\n",
    "        (0, 12),\n",
    "        (12, 18),\n",
    "        (18, 26),\n",
    "        (26, 36),\n",
    "        (36, 46),\n",
    "        (46, 60),\n",
    "        (60, 200)\n",
    "    ]),\n",
    "    \"Weight\": get_np_bins_and_labels([\n",
    "        (0, 55),\n",
    "        (55, 70),\n",
    "        (70, 80),\n",
    "        (80, 100),\n",
    "        (100, 120),\n",
    "        (120, 400)\n",
    "    ]),\n",
    "    \"Height\": get_np_bins_and_labels([\n",
    "        (0, 1.62),\n",
    "        (1.62, 1.75),\n",
    "        (1.75, 3.00)\n",
    "    ])\n",
    "}\n",
    "\n",
    "def bin_numerical_equally_by_frequency(\n",
    "    data: t.Union[npt.NDArray[np.float32], npt.NDArray[np.int32]], bins: int = 30\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs roughly equal binning based on the frequency of the items.\n",
    "    Example: For data = [1, 2, 3, 4, 5, 6, 7, 8, 9] and bins = 3, result will be (1, 3], (3, 6], (6, 9]\n",
    "    \"\"\"\n",
    "\n",
    "    if type(data[0]) is not np.float32 and type(data[0]) is not np.int32:\n",
    "        return data\n",
    "\n",
    "    result = pd.qcut(data, q=bins, duplicates=\"drop\").astype(\"string\")\n",
    "    return result\n",
    "\n",
    "def bin_on_predefined_way(data: t.Union[npt.NDArray[np.float32], npt.NDArray[np.int32]], predefined_bins: tuple[np.array, list[str]]):\n",
    "\n",
    "    if type(data[0]) is not np.float32 and type(data[0]) is not np.int32:\n",
    "        return data\n",
    "\n",
    "    return pd.cut(data, bins=predefined_bins[0], labels=predefined_bins[1], include_lowest=True)\n",
    "\n",
    "def bin_numerical_smartly(data_name: str, data: t.Union[npt.NDArray[np.float32], npt.NDArray[np.int32]], bins: int = 30):\n",
    "\n",
    "    if data_name not in predifined_bins:\n",
    "        return bin_numerical_equally_by_frequency(data, bins=bins)\n",
    "    else:\n",
    "        return bin_on_predefined_way(data, predifined_bins[data_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Algorithm utility functions\n",
    "\n",
    "Here we add utility functions for the algorithms to help us reduce code duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def run_apriori(\n",
    "    transactions: arules.ro.DataFrame, support: float, confidence: float\n",
    ") -> t.Optional[pd.DataFrame]:\n",
    "    try:\n",
    "        rules = arules.apriori(\n",
    "            transactions,\n",
    "            parameter=arules.parameters({\"supp\": support, \"conf\": confidence}),\n",
    "            control=arules.parameters({\"verbose\": False}),\n",
    "        )\n",
    "        return rules.as_df()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def run_apriori_build_html(\n",
    "    transactions: arules.ro.DataFrame, support: float, confidence: float\n",
    ") -> tuple[str, pd.DataFrame]:\n",
    "    result = \"\"\n",
    "\n",
    "    rules_dataframe = run_apriori(\n",
    "        transactions=transactions, support=support, confidence=confidence\n",
    "    )\n",
    "\n",
    "    result += f\"<h2>Result for Apriori run (support: {support}, confidence: {confidence})</h2>\"\n",
    "    result += (\n",
    "        rules_dataframe.to_html()\n",
    "        if rules_dataframe is not None\n",
    "        else \"<p>No rules were found</p>\"\n",
    "    )\n",
    "    result += \"</br>\"\n",
    "\n",
    "    return result, rules_dataframe\n",
    "\n",
    "\n",
    "def run_eclat(\n",
    "    transactions: arules.ro.DataFrame, support: float, confidence: float\n",
    ") -> t.Optional[pd.DataFrame]:\n",
    "    try:\n",
    "        rules = arules.eclat(\n",
    "            transactions,\n",
    "            parameter=arules.parameters({\"supp\": support}),\n",
    "            control=arules.parameters({\"verbose\": False}),\n",
    "        )\n",
    "        return rules.as_df()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def run_eclat_build_html(\n",
    "    transactions: arules.ro.DataFrame, support: float, confidence: float\n",
    ") -> tuple[str, pd.DataFrame]:\n",
    "    result = \"\"\n",
    "\n",
    "    rules_dataframe = run_eclat(\n",
    "        transactions=transactions, support=support, confidence=confidence\n",
    "    )\n",
    "\n",
    "    result += f\"<h2>Result for ECLAT run (support: {support})</h2>\"\n",
    "    result += (\n",
    "        rules_dataframe.to_html()\n",
    "        if rules_dataframe is not None\n",
    "        else \"<p>No rules were found</p>\"\n",
    "    )\n",
    "    result += \"</br>\"\n",
    "\n",
    "    return result, rules_dataframe\n",
    "\n",
    "def data_frame_to_html(title: str, data_frame: pd.DataFrame) -> str:\n",
    "    return f\"<h2>{title}</h2></br>{data_frame.to_html()}</br>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Preliminary data analysis\n",
    "\n",
    "Here we built plots for the data. Mostly for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for label in CATEGORICAL_VARIABLES_NO_LABEL:\n",
    "    pretty_label = LABEL_DICTIONARY[label]\n",
    "    dataset_subset_dataframe = dataset_dataframe[label].astype(str)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(dataset_subset_dataframe)\n",
    "    plt.xlabel(pretty_label)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for label in NUMERICAL_VARIABLES:\n",
    "    pretty_label = LABEL_DICTIONARY[label]\n",
    "    dataset_subset_dataframe = dataset_dataframe[label].astype(np.float32)\n",
    "    binned_data = bin_numerical_smartly(\n",
    "        data_name=label,\n",
    "        data=dataset_subset_dataframe, bins=10\n",
    "    )\n",
    "\n",
    "    plt.figure()\n",
    "    binned_data.value_counts().plot(kind=\"bar\", xlabel=label, ylabel=\"Count\", rot=90)\n",
    "    plt.xlabel(pretty_label)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Finding association rules\n",
    "\n",
    "Here we use the `arules` library to find association rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Categorical - categorical associations with Apriori algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    (0.7, 0.4),\n",
    "    (0.8, 0.8),\n",
    "    (0.9, 0.8),\n",
    "    (0.9, 0.9),\n",
    "    (0.95, 0.9),\n",
    "    (0.95, 0.95),\n",
    "]\n",
    "\n",
    "dataset_subset_dataframe = dataset_dataframe[CATEGORICAL_VARIABLES]\n",
    "transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "result_html = \"\"\n",
    "categorical_categorical_apriori = {}\n",
    "\n",
    "for support, confidence in parameters:\n",
    "    html_out, df_out = run_apriori_build_html(\n",
    "        transactions=transactions, support=support, confidence=confidence\n",
    "    )\n",
    "    result_html += html_out\n",
    "    categorical_categorical_apriori[(support, confidence)] = df_out\n",
    "\n",
    "HTML(result_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Categorial - categorial associations with ECLAT algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    (0.7, 0.4),\n",
    "    (0.8, 0.8),\n",
    "    (0.9, 0.8),\n",
    "    (0.9, 0.9),\n",
    "    (0.95, 0.9),\n",
    "    (0.95, 0.95),\n",
    "]\n",
    "\n",
    "dataset_subset_dataframe = dataset_dataframe[CATEGORICAL_VARIABLES]\n",
    "transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "result_html = \"\"\n",
    "categorical_categorical_eclat = {}\n",
    "\n",
    "for support, confidence in parameters:\n",
    "    html_out, df_out = run_eclat_build_html(\n",
    "        transactions=transactions, support=support, confidence=confidence\n",
    "    )\n",
    "    result_html += html_out\n",
    "    categorical_categorical_eclat[(support, confidence)] = df_out\n",
    "\n",
    "HTML(result_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Numerical - numerical associations with Apriori algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    (0.2, 0.4),\n",
    "    (0.25, 0.6),\n",
    "]\n",
    "\n",
    "dataset_subset_dataframe = dataset_dataframe[NUMERICAL_VARIABLES]\n",
    "dataset_subset_dataframe = dataset_subset_dataframe.apply(\n",
    "    lambda dataseries, label: bin_numerical_smartly(data_name=next(label), data=dataseries, bins=10),\n",
    "    args=(iter(dataset_subset_dataframe.columns), )\n",
    ")\n",
    "transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "result_html = \"\"\n",
    "numerical_numerical_apriori = {}\n",
    "\n",
    "for support, confidence in parameters:\n",
    "    html_out, df_out = run_apriori_build_html(\n",
    "        transactions=transactions, support=support, confidence=confidence\n",
    "    )\n",
    "    result_html += html_out\n",
    "    numerical_numerical_apriori[(support, confidence)] = df_out\n",
    "\n",
    "HTML(result_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Numerical - numerical associations with ECLAT algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    (0.2, 0.4),\n",
    "    (0.25, 0.6),\n",
    "]\n",
    "\n",
    "dataset_subset_dataframe = dataset_dataframe[NUMERICAL_VARIABLES]\n",
    "dataset_subset_dataframe = dataset_subset_dataframe.apply(\n",
    "    lambda dataseries, label: bin_numerical_smartly(data_name=next(label), data=dataseries, bins=10),\n",
    "    args=(iter(dataset_subset_dataframe.columns), )\n",
    ")\n",
    "transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "result_html = \"\"\n",
    "numerical_numerical_eclat = {}\n",
    "\n",
    "for support, confidence in parameters:\n",
    "    html_out, df_out = run_eclat_build_html(\n",
    "        transactions=transactions, support=support, confidence=confidence\n",
    "    )\n",
    "    result_html += html_out\n",
    "    numerical_numerical_eclat[(support, confidence)] = df_out\n",
    "\n",
    "HTML(result_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Categorical + numerical - categorical + numerical associations with Apriori algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    (0.4, 0.9),\n",
    "]\n",
    "\n",
    "dataset_subset_dataframe = dataset_dataframe[ALL_VARIABLES]\n",
    "dataset_subset_dataframe = dataset_subset_dataframe.apply(\n",
    "    lambda dataseries, label: bin_numerical_smartly(data_name=next(label), data=dataseries, bins=10),\n",
    "    args=(iter(dataset_subset_dataframe.columns), )\n",
    ")\n",
    "transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "result_html = \"\"\n",
    "catnum_catnum_apriori = {}\n",
    "\n",
    "for support, confidence in parameters:\n",
    "    html_out, df_out = run_apriori_build_html(\n",
    "        transactions=transactions, support=support, confidence=confidence\n",
    "    )\n",
    "    result_html += html_out\n",
    "    catnum_catnum_apriori[(support, confidence)] = df_out\n",
    "\n",
    "HTML(result_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Categorical + numerical - categorical + numerical associations with ECLAT algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    (0.4, 0.9),\n",
    "]\n",
    "\n",
    "dataset_subset_dataframe = dataset_dataframe[ALL_VARIABLES]\n",
    "dataset_subset_dataframe = dataset_subset_dataframe.apply(\n",
    "    lambda dataseries, label: bin_numerical_smartly(data_name=next(label), data=dataseries, bins=10),\n",
    "    args=(iter(dataset_subset_dataframe.columns), )\n",
    ")\n",
    "transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "result_html = \"\"\n",
    "catnum_catnum_eclat = {}\n",
    "\n",
    "for support, confidence in parameters:\n",
    "    html_out, df_out = run_eclat_build_html(\n",
    "        transactions=transactions, support=support, confidence=confidence\n",
    "    )\n",
    "    result_html += html_out\n",
    "    catnum_catnum_eclat[(support, confidence)] = df_out\n",
    "\n",
    "HTML(result_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_data = categorical_categorical_apriori[(0.8, 0.8)]\n",
    "\n",
    "def preprocess_str(arg_str: str) -> str:\n",
    "    arg_str = list(arg_str)\n",
    "    status = 0\n",
    "    for it in range(len(arg_str)):\n",
    "        if arg_str[it] == \",\" and status == 0:\n",
    "            arg_str[it] = \";\"\n",
    "        if arg_str[it] in [\"(\", \"[\"]:\n",
    "            status += 1\n",
    "        if arg_str[it] in [\")\", \"]\"]:\n",
    "            status -= 1\n",
    "    return \"\".join(arg_str)\n",
    "\n",
    "def get_assoc(assoc: str) -> list[tuple[str, str]]:\n",
    "    return [tuple(part.split(\"=\")) for part in list(filter(lambda x: x != \"\", preprocess_str(assoc[1:-1]).split(\";\")))]\n",
    "\n",
    "def distill_dataframe(arg_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    rules = {\n",
    "        \"LHS\": [],\n",
    "        \"RHS\": [],\n",
    "        \"support\": [],\n",
    "        \"confidence\": [],\n",
    "        \"coverage\": [],\n",
    "        \"lift\": [],\n",
    "        \"count\": []\n",
    "    }\n",
    "\n",
    "    for it in range(0, len(arg_data)):\n",
    "        lh_rule = get_assoc(arg_data[\"LHS\"][it])\n",
    "        rh_rule = get_assoc(arg_data[\"RHS\"][it])\n",
    "\n",
    "        if len(lh_rule) == 0 or len(rh_rule) == 0:\n",
    "            continue\n",
    "\n",
    "        rules[\"LHS\"].append(lh_rule)\n",
    "        rules[\"RHS\"].append(rh_rule)\n",
    "        rules[\"support\"].append(arg_data[\"support\"][it])\n",
    "        rules[\"confidence\"].append(arg_data[\"confidence\"][it])\n",
    "        rules[\"coverage\"].append(arg_data[\"coverage\"][it])\n",
    "        rules[\"lift\"].append(arg_data[\"lift\"][it])\n",
    "        rules[\"count\"].append(arg_data[\"count\"][it])\n",
    "\n",
    "\n",
    "    return pd.DataFrame(rules).sort_values(\"confidence\", ascending=False).reset_index(drop=True)[:10]\n",
    "\n",
    "\n",
    "def get_associations_with_label(assoc_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    rules = {\n",
    "        \"LHS\": [],\n",
    "        \"RHS\": [],\n",
    "        \"support\": [],\n",
    "        \"confidence\": [],\n",
    "        \"coverage\": [],\n",
    "        \"lift\": [],\n",
    "        \"count\": []\n",
    "    }\n",
    "\n",
    "    for it in range(len(assoc_data)):\n",
    "        lh_rule = assoc_data[\"LHS\"][it]\n",
    "        rh_rule = assoc_data[\"RHS\"][it]\n",
    "\n",
    "        if len(rh_rule) != 1 or rh_rule[0][0] != LABEL_VARIABLE:\n",
    "            continue\n",
    "\n",
    "        rules[\"LHS\"].append(lh_rule)\n",
    "        rules[\"RHS\"].append(rh_rule)\n",
    "        rules[\"support\"].append(assoc_data[\"support\"][it])\n",
    "        rules[\"confidence\"].append(assoc_data[\"confidence\"][it])\n",
    "        rules[\"coverage\"].append(assoc_data[\"coverage\"][it])\n",
    "        rules[\"lift\"].append(assoc_data[\"lift\"][it])\n",
    "        rules[\"count\"].append(assoc_data[\"count\"][it])\n",
    "\n",
    "    return pd.DataFrame(rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Categorical - Categorical top rules with Apriori algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distyled_categorical_categorical_apriori = distill_dataframe(categorical_categorical_apriori[(0.7, 0.4)])\n",
    "\n",
    "HTML(data_frame_to_html(\"Categorical - Categorical top rules with Apriori algorithm\", distyled_categorical_categorical_apriori))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Numerical - Numerical top rules with Apriori algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distyled_numerical_numerical_apriori = distill_dataframe(numerical_numerical_apriori[(0.2, 0.4)])\n",
    "\n",
    "HTML(data_frame_to_html(\"Numerical - Numerical top rules with Apriori algorithm\", distyled_numerical_numerical_apriori))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Categorical + Numerical - Categorical + Numerical top rules with Apriori algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distyled_catnum_catnum_apriori = distill_dataframe(catnum_catnum_apriori[(0.4, 0.9)])\n",
    "\n",
    "HTML(data_frame_to_html(\"Categorical + Numerical - Categorical + Numerical top rules with Apriori algorithm\", distyled_catnum_catnum_apriori))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Categorical - Label associations with Apriori algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    (0.05, 0.05)\n",
    "]\n",
    "\n",
    "result = \"\"\n",
    "catlabel_df = None\n",
    "\n",
    "for cat in CATEGORICAL_VARIABLES_NO_LABEL:\n",
    "\n",
    "    dataset_subset_dataframe = dataset_dataframe[[LABEL_VARIABLE, cat]]\n",
    "    transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "\n",
    "    for support, confidence in parameters:\n",
    "        html_out, df_out =  run_apriori_build_html(\n",
    "            transactions=transactions, support=support, confidence=confidence\n",
    "        )\n",
    "\n",
    "        df_out = get_associations_with_label(distill_dataframe(df_out))\n",
    "\n",
    "        if catlabel_df is not None:\n",
    "            catlabel_df = pd.concat([catlabel_df, df_out])\n",
    "        else:\n",
    "            catlabel_df = df_out\n",
    "\n",
    "catlabel_df = catlabel_df.sort_values(\"confidence\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "HTML(data_frame_to_html(\"Categorical to Label Top Rules\", catlabel_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Numerical - Label associations with Apriori algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    (0.05, 0.05)\n",
    "]\n",
    "\n",
    "result = \"\"\n",
    "numlabel_df = None\n",
    "\n",
    "for num in NUMERICAL_VARIABLES:\n",
    "\n",
    "    dataset_subset_dataframe = dataset_dataframe[[LABEL_VARIABLE, num]]\n",
    "\n",
    "    dataset_subset_dataframe = dataset_subset_dataframe.apply(\n",
    "        lambda dataseries, label: bin_numerical_smartly(data_name=next(label), data=dataseries, bins=10),\n",
    "        args=(iter(dataset_subset_dataframe.columns), )\n",
    "    )\n",
    "\n",
    "    transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "\n",
    "    result = \"\"\n",
    "\n",
    "    for support, confidence in parameters:\n",
    "        html_out, df_out =  run_apriori_build_html(\n",
    "            transactions=transactions, support=support, confidence=confidence\n",
    "        )\n",
    "\n",
    "        df_out = get_associations_with_label(distill_dataframe(df_out))\n",
    "\n",
    "        if numlabel_df is not None:\n",
    "            numlabel_df = pd.concat([numlabel_df, df_out])\n",
    "        else:\n",
    "            numlabel_df = df_out\n",
    "\n",
    "numlabel_df = numlabel_df.sort_values(\"confidence\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "HTML(data_frame_to_html(\"Numerical to Label Top Rules\", numlabel_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Visualisations\n",
    "\n",
    "Here we visualise the rules we found using the algorithms above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_single_association(arg_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    arg_data = copy.deepcopy(arg_data)\n",
    "\n",
    "    rules = {\n",
    "        \"LHS\": [],\n",
    "        \"RHS\": [],\n",
    "        \"support\": [],\n",
    "        \"confidence\": [],\n",
    "        \"coverage\": [],\n",
    "        \"lift\": [],\n",
    "        \"count\": []\n",
    "    }\n",
    "\n",
    "    for it in range(0, len(arg_data)):\n",
    "        lh_rule = arg_data[\"LHS\"][it]\n",
    "        rh_rule = arg_data[\"RHS\"][it]\n",
    "\n",
    "        if len(lh_rule) != 1 or len(rh_rule) != 1:\n",
    "            continue\n",
    "\n",
    "        rules[\"LHS\"].append(lh_rule[0])\n",
    "        rules[\"RHS\"].append(rh_rule[0])\n",
    "        rules[\"support\"].append(arg_data[\"support\"][it])\n",
    "        rules[\"confidence\"].append(arg_data[\"confidence\"][it])\n",
    "        rules[\"coverage\"].append(arg_data[\"coverage\"][it])\n",
    "        rules[\"lift\"].append(arg_data[\"lift\"][it])\n",
    "        rules[\"count\"].append(arg_data[\"count\"][it])\n",
    "\n",
    "    return pd.DataFrame(rules)\n",
    "\n",
    "\n",
    "def strip_variables_categories(arg_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    arg_data = copy.deepcopy(arg_data)\n",
    "    for it in range(0, len(arg_data)):\n",
    "        arg_data[\"LHS\"][it] = arg_data[\"LHS\"][it][0]\n",
    "        arg_data[\"RHS\"][it] = arg_data[\"RHS\"][it][0]\n",
    "    return arg_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Categorical - Categorical CatPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_categorical_catplot_df = get_single_association(distyled_categorical_categorical_apriori)\n",
    "\n",
    "\n",
    "colors=['green','grey','orange']\n",
    "catscatter(categorical_categorical_catplot_df,'LHS','RHS','confidence', color=colors,ratio=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Numerical - Numerical CatPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numerical_numerical_catplot_df = get_single_association(distyled_numerical_numerical_apriori)\n",
    "\n",
    "\n",
    "colors=['green','grey','orange']\n",
    "catscatter(numerical_numerical_catplot_df,'LHS','RHS','confidence', color=colors,ratio=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Categorical - categorial visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_subset_dataframe = dataset_dataframe[CATEGORICAL_VARIABLES]\n",
    "transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "\n",
    "rules = arules.apriori(\n",
    "    transactions,\n",
    "    parameter=arules.parameters({\"supp\": 0.5, \"conf\": 0.90}),\n",
    "    control=arules.parameters({\"verbose\": False}),\n",
    ")\n",
    "\n",
    "gg = plot(rules, method=\"scatter\")\n",
    "image_png(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_subset_dataframe = dataset_dataframe[CATEGORICAL_VARIABLES]\n",
    "transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "\n",
    "rules = arules.apriori(\n",
    "    transactions,\n",
    "    parameter=arules.parameters({\"supp\": 0.7, \"conf\": 0.90}),\n",
    "    control=arules.parameters({\"verbose\": False}),\n",
    ")\n",
    "\n",
    "#gg = plot(rules, method=\"grouped\")\n",
    "#image_png(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_subset_dataframe = dataset_dataframe[CATEGORICAL_VARIABLES]\n",
    "transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "\n",
    "rules = arules.apriori(\n",
    "    transactions,\n",
    "    parameter=arules.parameters({\"supp\": 0.5, \"conf\": 0.90}),\n",
    "    control=arules.parameters({\"verbose\": False}),\n",
    ")\n",
    "\n",
    "rules_20 = rules.sort(by = 'confidence')[0:100]\n",
    "gg = plot(rules_20, method=\"graph\")\n",
    "image_png(gg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical - numerical visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_subset_dataframe = dataset_dataframe[NUMERICAL_VARIABLES]\n",
    "transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "\n",
    "rules = arules.apriori(\n",
    "    transactions,\n",
    "    parameter=arules.parameters({\"supp\": 0.2, \"conf\": 0.4}),\n",
    "    control=arules.parameters({\"verbose\": False}),\n",
    ")\n",
    "\n",
    "gg = plot(rules, method=\"scatter\")\n",
    "image_png(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_subset_dataframe = dataset_dataframe[NUMERICAL_VARIABLES]\n",
    "transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "\n",
    "rules = arules.apriori(\n",
    "    transactions,\n",
    "    parameter=arules.parameters({\"supp\": 0.2, \"conf\": 0.4}),\n",
    "    control=arules.parameters({\"verbose\": False}),\n",
    ")\n",
    "\n",
    "gg = plot(rules, method=\"grouped\")\n",
    "image_png(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_subset_dataframe = dataset_dataframe[NUMERICAL_VARIABLES]\n",
    "transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "\n",
    "rules = arules.apriori(\n",
    "    transactions,\n",
    "    parameter=arules.parameters({\"supp\": 0.2, \"conf\": 0.2}),\n",
    "    control=arules.parameters({\"verbose\": False}),\n",
    ")\n",
    "\n",
    "rules_20 = rules.sort(by = 'confidence')[0:20]\n",
    "gg = plot(rules_20, method=\"graph\")\n",
    "image_png(gg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical + numerical - categorical + numerical visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_subset_dataframe = dataset_dataframe[ALL_VARIABLES]\n",
    "transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "\n",
    "rules = arules.apriori(\n",
    "    transactions,\n",
    "    parameter=arules.parameters({\"supp\": 0.2, \"conf\": 0.4}),\n",
    "    control=arules.parameters({\"verbose\": False}),\n",
    ")\n",
    "\n",
    "gg = plot(rules, method=\"scatter\")\n",
    "image_png(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_subset_dataframe = dataset_dataframe[ALL_VARIABLES]\n",
    "transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "\n",
    "rules = arules.apriori(\n",
    "    transactions,\n",
    "    parameter=arules.parameters({\"supp\": 0.2, \"conf\": 0.2}),\n",
    "    control=arules.parameters({\"verbose\": False}),\n",
    ")\n",
    "\n",
    "rules_20 = rules.sort(by = 'confidence')[0:20]\n",
    "gg = plot(rules_20, method=\"graph\")\n",
    "image_png(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_subset_dataframe = dataset_dataframe[ALL_VARIABLES]\n",
    "transactions = arules.Transactions.from_df(dataset_subset_dataframe)\n",
    "\n",
    "rules = arules.apriori(\n",
    "    transactions,\n",
    "    parameter=arules.parameters({\"supp\": 0.2, \"conf\": 0.2}),\n",
    "    control=arules.parameters({\"verbose\": False}),\n",
    ")\n",
    "\n",
    "rules_20 = rules.sort(by = 'confidence')[0:20]\n",
    "gg = plot(rules_20, method=\"graph\")\n",
    "image_png(gg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catscatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catlabel_df_catscat = get_single_association(catlabel_df)\n",
    "\n",
    "\n",
    "colors=['green','grey','orange']\n",
    "catscatter(catlabel_df_catscat,'LHS','RHS','confidence', color=colors,ratio=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numlabel_df_catscat = get_single_association(numlabel_df)\n",
    "\n",
    "\n",
    "colors=['green','grey','orange']\n",
    "catscatter(numlabel_df_catscat,'LHS','RHS','confidence', color=colors,ratio=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
