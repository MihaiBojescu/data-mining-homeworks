{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 - classifiers\n",
    "\n",
    "In this homework we will use 7 algorithms to classify data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite knowledge\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    Precision &= \\frac{\\text{True positives}}{\\text{True positives} + \\text{False positives}} \\\\\n",
    "    Recall &= \\frac{\\text{True positives}}{\\text{True positives} + \\text{False negatives}} \\\\\n",
    "    F1 &= 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**Note**: This is mostly for learning purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import platform\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    os.environ[\"R_HOME\"] = \"C:\\Program Files\\R\\R-4.3.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "import csv\n",
    "import itertools\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "from IPython.display import display, HTML, IFrame\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset-specific dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_VARIABLE = \"NObeyesdad\"\n",
    "NUMERICAL_VARIABLES = [\"Age\", \"Height\", \"Weight\", \"FCVC\", \"NCP\", \"CH2O\", \"FAF\", \"TUE\"]\n",
    "CATEGORICAL_VARIABLES_NO_LABEL = [\n",
    "    \"FAVC\",\n",
    "    \"CAEC\",\n",
    "    \"CALC\",\n",
    "    \"SCC\",\n",
    "    \"MTRANS\",\n",
    "    \"Gender\",\n",
    "    \"family_history_with_overweight\",\n",
    "    \"SMOKE\",\n",
    "]\n",
    "CATEGORICAL_VARIABLES = [\n",
    "    *CATEGORICAL_VARIABLES_NO_LABEL,\n",
    "    LABEL_VARIABLE,\n",
    "]\n",
    "ALL_VARIABLES_NO_LABEL = [*NUMERICAL_VARIABLES, *CATEGORICAL_VARIABLES_NO_LABEL]\n",
    "ALL_VARIABLES = [*NUMERICAL_VARIABLES, *CATEGORICAL_VARIABLES]\n",
    "LABEL_DICTIONARY = {\n",
    "    \"Age\": \"Age\",\n",
    "    \"Height\": \"Height (cm)\",\n",
    "    \"Weight\": \"Weight (kg)\",\n",
    "    \"FCVC\": \" Frequency of consumption of vegetables (times per day)\",\n",
    "    \"NCP\": \"Number of main meals\",\n",
    "    \"CH2O\": \"Consumption of water daily (Liters)\",\n",
    "    \"FAF\": \"Physical activity frequency (times per day)\",\n",
    "    \"TUE\": \"Time using technology devices (hours)\",\n",
    "    \"FAVC\": \"Frequent consumption of high caloric food\",\n",
    "    \"CAEC\": \"Consumption of food between meals\",\n",
    "    \"CALC\": \"Consumption of alcohol\",\n",
    "    \"SCC\": \"Calories consumption monitoring\",\n",
    "    \"MTRANS\": \"Transportation used\",\n",
    "    \"Gender\": \"Gender\",\n",
    "    \"family_history_with_overweight\": \"Family member suffered or suffers from overweight\",\n",
    "    \"SMOKE\": \"Smoker or not\",\n",
    "    \"NObeyesdad\": \"Obesity level\",\n",
    "}\n",
    "\n",
    "T = t.TypeVar(\"T\")\n",
    "\n",
    "\n",
    "class Person:\n",
    "    Gender: str\n",
    "    Age: np.int32\n",
    "    Height: np.float32\n",
    "    Weight: np.float32\n",
    "    family_history_with_overweight: str\n",
    "    FAVC: str\n",
    "    FCVC: np.float32\n",
    "    NCP: np.float32\n",
    "    CAEC: str\n",
    "    SMOKE: str\n",
    "    CH2O: np.float32\n",
    "    SCC: str\n",
    "    FAF: np.float32\n",
    "    TUE: np.float32\n",
    "    CALC: str\n",
    "    MTRANS: str\n",
    "    NObeyesdad: str\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        Gender: str,\n",
    "        Age: str,\n",
    "        Height: str,\n",
    "        Weight: str,\n",
    "        family_history_with_overweight: str,\n",
    "        FAVC: str,\n",
    "        FCVC: str,\n",
    "        NCP: str,\n",
    "        CAEC: str,\n",
    "        SMOKE: str,\n",
    "        CH2O: str,\n",
    "        SCC: str,\n",
    "        FAF: str,\n",
    "        TUE: str,\n",
    "        CALC: str,\n",
    "        MTRANS: str,\n",
    "        NObeyesdad: str,\n",
    "    ):\n",
    "        self.Gender = Gender\n",
    "        self.Age = np.float32(Age)\n",
    "        self.Height = np.float32(Height)\n",
    "        self.Weight = np.float32(Weight)\n",
    "        self.family_history_with_overweight = family_history_with_overweight\n",
    "        self.FAVC = FAVC\n",
    "        self.FCVC = np.float32(FCVC)\n",
    "        self.NCP = np.float32(NCP)\n",
    "        self.CAEC = CAEC\n",
    "        self.SMOKE = SMOKE\n",
    "        self.CH2O = np.float32(CH2O)\n",
    "        self.SCC = SCC\n",
    "        self.FAF = np.float32(FAF)\n",
    "        self.TUE = np.float32(TUE)\n",
    "        self.CALC = CALC\n",
    "        self.MTRANS = MTRANS\n",
    "        self.NObeyesdad = NObeyesdad\n",
    "\n",
    "    def __str__(self):\n",
    "        return vars(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(vars(self))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return vars(self)\n",
    "\n",
    "\n",
    "class DatasetManager:\n",
    "    def __init__(self, path_to_csv: str):\n",
    "        self.path_to_csv = path_to_csv\n",
    "\n",
    "    def load_as_obj_list(self) -> list[Person]:\n",
    "        with open(self.path_to_csv) as csv_file:\n",
    "            csv_reader = csv.DictReader(csv_file)\n",
    "            return [Person(**row) for row in csv_reader]\n",
    "\n",
    "    def make_label_combinations(self, labels: t.List[str], k: int = 2):\n",
    "        result: t.List[t.Tuple[str, ...]] = []\n",
    "\n",
    "        for combination in itertools.combinations(labels, k):\n",
    "            result.append(list(combination))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def labels_to_onehot(\n",
    "        self, dataframe: pd.DataFrame, labels: t.List[str]\n",
    "    ) -> pd.DataFrame:\n",
    "        return pd.get_dummies(dataframe[labels], drop_first=True)\n",
    "    \n",
    "    def sample(\n",
    "        self, dataframe: pd.DataFrame, frac: float, random_state: t.Optional[int] = 42\n",
    "    ):\n",
    "        sample = dataframe.sample(frac=frac, random_state=random_state)\n",
    "        sample_extra = dataframe.drop(sample.index)\n",
    "\n",
    "        return (sample, sample_extra)\n",
    "\n",
    "    def compute_metrics(self, y_true: pd.DataFrame, y_hat: pd.DataFrame):\n",
    "        precision = precision_score(y_true, y_hat, average='micro')\n",
    "        recall = recall_score(y_true, y_hat, average='micro')\n",
    "        f1 = f1_score(y_true, y_hat, average='micro')\n",
    "\n",
    "        result = pd.DataFrame({\n",
    "            \"Precision score\": [precision],\n",
    "            \"Recall score\": [recall],\n",
    "            \"F1 score\": [f1],\n",
    "        })\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotManager:\n",
    "    def __init__(self, cols: int, samples: int) -> None:\n",
    "        self.rows = samples // cols + 1\n",
    "        self.cols = cols\n",
    "        self.samples = samples\n",
    "        self.index = 0\n",
    "\n",
    "        fig = plt.figure()\n",
    "        fig, axs = plt.subplots(self.rows, self.cols)\n",
    "        plt.tight_layout(h_pad=2, w_pad=2, pad=0)\n",
    "\n",
    "        self.fig = fig\n",
    "        self.axs = axs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        subplot_i = i // (self.rows - 1)\n",
    "        subplot_j = i % self.cols\n",
    "        subplot = (subplot_i, subplot_j)\n",
    "\n",
    "        return self.axs[subplot]\n",
    "\n",
    "    def __next__(self):\n",
    "        subplot_i = self.index // (self.rows - 1)\n",
    "        subplot_j = self.index % self.cols\n",
    "        subplot = (subplot_i, subplot_j)\n",
    "\n",
    "        self.index += 1\n",
    "\n",
    "        return self.axs[subplot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_manager = DatasetManager(\"data/ObesityDataSet.csv\")\n",
    "dataset_obj_list = dataset_manager.load_as_obj_list()\n",
    "dataset_dataframe = pd.DataFrame.from_records(\n",
    "    data=[vars(entry) for entry in dataset_obj_list]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Properly implement this\n",
    "def generate_k_folds(X: pd.DataFrame, Y: pd.DataFrame, k: int = 8):\n",
    "    random_state=42\n",
    "\n",
    "    X_train, X_test = dataset_manager.sample(\n",
    "        dataframe=X, frac=0.8, random_state=random_state\n",
    "    )\n",
    "    Y_train, Y_test = dataset_manager.sample(\n",
    "        dataframe=Y, frac=0.8, random_state=random_state\n",
    "    )\n",
    "\n",
    "    return [(X_train, X_test, Y_train, Y_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform better selection\n",
    "\n",
    "SELECTED_FEATURES = [\n",
    "    \"NCP\",\n",
    "    \"Height\",\n",
    "    \"Weight\",\n",
    "    \"FAVC\",\n",
    "    \"family_history_with_overweight\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_combinations = dataset_manager.make_label_combinations(SELECTED_FEATURES)\n",
    "random_state = np.random.randint(low=0, high=100)\n",
    "params_sets = [\n",
    "    {\"criterion\": \"gini\", \"splitter\": \"best\"},\n",
    "    {\"criterion\": \"gini\", \"splitter\": \"random\"},\n",
    "]\n",
    "\n",
    "for params_set in params_sets:\n",
    "    plot_manager = PlotManager(cols=3, samples=len(label_combinations))\n",
    "\n",
    "    display(HTML(f\"<h1>Decision trees classifier</h1>\"))\n",
    "    display(HTML(f\"<p>Parameters: {params_set}, random state: {random_state}.</p>\"))\n",
    "\n",
    "    for i, label_combination in enumerate(label_combinations):\n",
    "        subplot = plot_manager[i]\n",
    "        label_encoder = LabelEncoder()\n",
    "        best_classifier = None\n",
    "        best_metrics = pd.DataFrame({\n",
    "            \"Precision score\": [0],\n",
    "            \"Recall score\": [0],\n",
    "            \"F1 score\": [0]\n",
    "        })\n",
    "\n",
    "        X = dataset_manager.labels_to_onehot(dataset_dataframe, label_combination)\n",
    "        Y = dataset_dataframe[LABEL_VARIABLE]\n",
    "        Y_encoded = label_encoder.fit_transform(Y)\n",
    "\n",
    "        for X_train, X_test, Y_train, Y_test in generate_k_folds(X=X, Y=Y):\n",
    "            classifier = tree.DecisionTreeClassifier(\n",
    "                criterion=params_set[\"criterion\"], splitter=params_set[\"splitter\"]\n",
    "            )\n",
    "            classifier = classifier.fit(X_train, Y_train)\n",
    "\n",
    "            Y_hat = classifier.predict(X_test)\n",
    "            Y_hat = pd.DataFrame({LABEL_VARIABLE: Y_hat})\n",
    "\n",
    "            metrics = dataset_manager.compute_metrics(\n",
    "                y_true=Y_test, y_hat=Y_hat\n",
    "            )\n",
    "\n",
    "            if metrics[\"F1 score\"][0] > best_metrics[\"F1 score\"][0]:\n",
    "                best_metrics = metrics\n",
    "                best_classifier = classifier\n",
    "\n",
    "        DecisionBoundaryDisplay.from_estimator(\n",
    "            best_classifier,\n",
    "            X,\n",
    "            cmap=plt.cm.RdYlBu,\n",
    "            response_method=\"predict\",\n",
    "            ax=subplot,\n",
    "            xlabel=label_combination[0],\n",
    "            ylabel=label_combination[1],\n",
    "        )\n",
    "\n",
    "        subplot.scatter(\n",
    "            X[X.columns[0]],\n",
    "            X[X.columns[1]],\n",
    "            c=Y_encoded,\n",
    "            cmap=plt.cm.RdYlBu,\n",
    "            linewidths=0.25,\n",
    "            edgecolor=\"black\",\n",
    "            s=5,\n",
    "        )\n",
    "\n",
    "        display(HTML(f\"<p>For input label combination {label_combination} and output label '{LABEL_VARIABLE}', best metrics were:</p>\"))\n",
    "        display(best_metrics)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RandomForest or ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_combinations = dataset_manager.make_label_combinations(SELECTED_FEATURES)\n",
    "random_state = np.random.randint(low=0, high=100)\n",
    "params_sets = [\n",
    "    {\"criterion\": \"gini\", \"splitter\": \"best\"},\n",
    "    {\"criterion\": \"gini\", \"splitter\": \"random\"},\n",
    "]\n",
    "\n",
    "for params_set in params_sets:\n",
    "    plot_manager = PlotManager(cols=3, samples=len(label_combinations))\n",
    "\n",
    "    display(HTML(f\"<h1>Decision trees classifier</h1>\"))\n",
    "    display(HTML(f\"<p>Parameters: {params_set}, random state: {random_state}.</p>\"))\n",
    "\n",
    "    for i, label_combination in enumerate(label_combinations):\n",
    "        subplot = plot_manager[i]\n",
    "        label_encoder = LabelEncoder()\n",
    "        best_classifier = None\n",
    "        best_metrics = pd.DataFrame({\n",
    "            \"Precision score\": [0],\n",
    "            \"Recall score\": [0],\n",
    "            \"F1 score\": [0]\n",
    "        })\n",
    "\n",
    "        X = dataset_manager.labels_to_onehot(dataset_dataframe, label_combination)\n",
    "        Y = dataset_dataframe[LABEL_VARIABLE]\n",
    "        Y_encoded = label_encoder.fit_transform(Y)\n",
    "\n",
    "        for X_train, X_test, Y_train, Y_test in generate_k_folds(X=X, Y=Y):\n",
    "            classifier = tree.ExtraTreeClassifier(\n",
    "                criterion=params_set[\"criterion\"], splitter=params_set[\"splitter\"]\n",
    "            )\n",
    "            classifier = classifier.fit(X_train, Y_train)\n",
    "\n",
    "            Y_hat = classifier.predict(X_test)\n",
    "            Y_hat = pd.DataFrame({LABEL_VARIABLE: Y_hat})\n",
    "\n",
    "            metrics = dataset_manager.compute_metrics(\n",
    "                y_true=Y_test, y_hat=Y_hat\n",
    "            )\n",
    "\n",
    "            if metrics[\"F1 score\"][0] > best_metrics[\"F1 score\"][0]:\n",
    "                best_metrics = metrics\n",
    "                best_classifier = classifier\n",
    "\n",
    "        DecisionBoundaryDisplay.from_estimator(\n",
    "            best_classifier,\n",
    "            X,\n",
    "            cmap=plt.cm.RdYlBu,\n",
    "            response_method=\"predict\",\n",
    "            ax=subplot,\n",
    "            xlabel=label_combination[0],\n",
    "            ylabel=label_combination[1],\n",
    "        )\n",
    "\n",
    "        subplot.scatter(\n",
    "            X[X.columns[0]],\n",
    "            X[X.columns[1]],\n",
    "            c=Y_encoded,\n",
    "            cmap=plt.cm.RdYlBu,\n",
    "            linewidths=0.25,\n",
    "            edgecolor=\"black\",\n",
    "            s=5,\n",
    "        )\n",
    "\n",
    "        display(HTML(f\"<p>For input label combination {label_combination} and output label '{LABEL_VARIABLE}', best metrics were:</p>\"))\n",
    "        display(best_metrics)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_combinations = dataset_manager.make_label_combinations(SELECTED_FEATURES)\n",
    "random_state = np.random.randint(low=0, high=100)\n",
    "params_sets = [\n",
    "    {\"criterion\": \"gini\", \"splitter\": \"best\"},\n",
    "    {\"criterion\": \"gini\", \"splitter\": \"random\"},\n",
    "]\n",
    "\n",
    "for params_set in params_sets:\n",
    "    plot_manager = PlotManager(cols=3, samples=len(label_combinations))\n",
    "\n",
    "    display(HTML(f\"<h1>Decision trees classifier</h1>\"))\n",
    "    display(HTML(f\"<p>Parameters: {params_set}, random state: {random_state}.</p>\"))\n",
    "\n",
    "    for i, label_combination in enumerate(label_combinations):\n",
    "        subplot = plot_manager[i]\n",
    "        label_encoder = LabelEncoder()\n",
    "        best_classifier = None\n",
    "        best_metrics = pd.DataFrame({\n",
    "            \"Precision score\": [0],\n",
    "            \"Recall score\": [0],\n",
    "            \"F1 score\": [0]\n",
    "        })\n",
    "\n",
    "        X = dataset_manager.labels_to_onehot(dataset_dataframe, label_combination)\n",
    "        Y = dataset_dataframe[LABEL_VARIABLE]\n",
    "        Y_encoded = label_encoder.fit_transform(Y)\n",
    "\n",
    "        for X_train, X_test, Y_train, Y_test in generate_k_folds(X=X, Y=Y):\n",
    "            classifier = tree.ExtraTreeClassifier(\n",
    "                criterion=params_set[\"criterion\"], splitter=params_set[\"splitter\"]\n",
    "            )\n",
    "            classifier = classifier.fit(X_train, Y_train)\n",
    "\n",
    "            Y_hat = classifier.predict(X_test)\n",
    "            Y_hat = pd.DataFrame({LABEL_VARIABLE: Y_hat})\n",
    "\n",
    "            metrics = dataset_manager.compute_metrics(\n",
    "                y_true=Y_test, y_hat=Y_hat\n",
    "            )\n",
    "\n",
    "            if metrics[\"F1 score\"][0] > best_metrics[\"F1 score\"][0]:\n",
    "                best_metrics = metrics\n",
    "                best_classifier = classifier\n",
    "\n",
    "        DecisionBoundaryDisplay.from_estimator(\n",
    "            best_classifier,\n",
    "            X,\n",
    "            cmap=plt.cm.RdYlBu,\n",
    "            response_method=\"predict\",\n",
    "            ax=subplot,\n",
    "            xlabel=label_combination[0],\n",
    "            ylabel=label_combination[1],\n",
    "        )\n",
    "\n",
    "        subplot.scatter(\n",
    "            X[X.columns[0]],\n",
    "            X[X.columns[1]],\n",
    "            c=Y_encoded,\n",
    "            cmap=plt.cm.RdYlBu,\n",
    "            linewidths=0.25,\n",
    "            edgecolor=\"black\",\n",
    "            s=5,\n",
    "        )\n",
    "\n",
    "        display(HTML(f\"<p>For input label combination {label_combination} and output label '{LABEL_VARIABLE}', best metrics were:</p>\"))\n",
    "        display(best_metrics)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
